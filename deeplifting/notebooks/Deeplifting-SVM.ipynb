{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "da720180-4028-49ad-9886-f139cc0b71c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/ryandevera/data-science/umn_environments/Deeplifting/deeplifting/notebooks'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9ba49b7f-d35d-4d6d-9808-f6cf773c0313",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/ryandevera/data-science/umn_environments/Deeplifting\n"
     ]
    }
   ],
   "source": [
    "%cd ../.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d41873e7-5036-4bf0-a8bd-d038da320819",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deeplifting.models import DeepliftingSkipMLP\n",
    "from sklearn.datasets import load_iris\n",
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# import pygranso functions\n",
    "from pygranso.private.getNvar import getNvarTorch\n",
    "from pygranso.pygranso import pygranso\n",
    "from pygranso.pygransoStruct import pygransoStruct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "76c23967-68e1-45b1-a039-e4eaf30e15ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cpu')\n",
    "\n",
    "# Load the dataset\n",
    "iris = load_iris()\n",
    "\n",
    "# The data and target labels\n",
    "data = iris.data\n",
    "labels = iris.target\n",
    "\n",
    "# If you want the feature names and target names:\n",
    "feature_names = iris.feature_names\n",
    "target_names = iris.target_names\n",
    "\n",
    "df = pd.DataFrame(data=iris.data, columns=['f1', 'f2', 'f3', 'f4'])\n",
    "df['f5'] = 1.0\n",
    "df['target'] = iris.target\n",
    "\n",
    "df = df.sample(frac=1.0).reset_index(drop=True)\n",
    "\n",
    "# Dimensions\n",
    "output_size = len(feature_names) + 1\n",
    "\n",
    "# Inputs\n",
    "inputs_X = df[['f1', 'f2', 'f3', 'f4', 'f5']].values\n",
    "inputs_X = torch.from_numpy(inputs_X).to(device=device, dtype=torch.double).T\n",
    "\n",
    "# Just two classes for now\n",
    "labels = df['target'].values\n",
    "\n",
    "y = np.zeros(len(labels))\n",
    "y[labels != 1] = 1\n",
    "y[labels == 1] = -1\n",
    "y = torch.from_numpy(y).to(device=device, dtype=torch.double)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aa6b21b2-8b24-48f1-9abf-ee958fc7d19b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([5, 150]), (150,))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs_X.shape, labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "401fb869-5bd8-4238-8a15-d5c683bf21fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the learning function\n",
    "def deeplifting_svm(model, inputs_X, labels):\n",
    "    outputs = model(None)\n",
    "    weight_vec = outputs.mean(axis=0)\n",
    "\n",
    "    # Compute SVM objective\n",
    "    denominator = torch.linalg.norm(weight_vec, ord=2)\n",
    "    prod = torch.matmul(weight_vec.T, inputs_X)\n",
    "    numerator = labels * prod\n",
    "    obj = numerator / denominator\n",
    "\n",
    "    # Orig obj\n",
    "    f = torch.amax(-1 * obj)\n",
    "\n",
    "    ce = None\n",
    "    ci = None\n",
    "    return f, ci, ce\n",
    "\n",
    "\n",
    "# Set up a model\n",
    "# Deeplifting model with skip connections\n",
    "model = DeepliftingSkipMLP(\n",
    "    input_size=1,\n",
    "    hidden_sizes=(64,) * 2,\n",
    "    output_size=output_size,\n",
    "    bounds=None,\n",
    "    skip_every_n=1,\n",
    "    activation='relu',\n",
    "    output_activation='sine',\n",
    "    agg_function='sum',\n",
    "    include_bn=True,\n",
    "    seed=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ec2ef475-a515-4720-94e8-a7c3b99dee94",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/6c/8rvpvzfs0vxbbx2jh4rbfb100000gn/T/ipykernel_80105/2917230463.py:8: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matrices or `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3575.)\n",
      "  prod = torch.matmul(weight_vec.T, inputs_X)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[33m╔═════ QP SOLVER NOTICE ════════════════════════════════════════════════════════════════════════╗\n",
      "\u001b[0m\u001b[33m║  PyGRANSO requires a quadratic program (QP) solver that has a quadprog-compatible interface,  ║\n",
      "\u001b[0m\u001b[33m║  the default is osqp. Users may provide their own wrapper for the QP solver.                  ║\n",
      "\u001b[0m\u001b[33m║  To disable this notice, set opts.quadprog_info_msg = False                                   ║\n",
      "\u001b[0m\u001b[33m╚═══════════════════════════════════════════════════════════════════════════════════════════════╝\n",
      "\u001b[0m══════════════════════════════════════════════════════════════════════════════════════════════╗\n",
      "PyGRANSO: A PyTorch-enabled port of GRANSO with auto-differentiation                          ║ \n",
      "Version 1.2.0                                                                                 ║ \n",
      "Licensed under the AGPLv3, Copyright (C) 2021-2022 Tim Mitchell and Buyun Liang               ║ \n",
      "══════════════════════════════════════════════════════════════════════════════════════════════╣\n",
      "Problem specifications:                                                                       ║ \n",
      " # of variables                     :   17683                                                 ║ \n",
      " # of inequality constraints        :       0                                                 ║ \n",
      " # of equality constraints          :       0                                                 ║ \n",
      "══════════════════════════════════════════════════════════════════════════════════════════════╣\n",
      "\u001b[33mLimited-memory mode enabled with size = 5.                                                   \u001b[0m ║ \n",
      "\u001b[33mNOTE: limited-memory mode is generally NOT                                                   \u001b[0m ║ \n",
      "\u001b[33mrecommended for nonsmooth problems.                                                          \u001b[0m ║ \n",
      "═════╦════════════╦════════════════╦═════════════╦═══════════════════════╦════════════════════╣\n",
      "     ║ Penalty Fn ║                ║  Violation  ║ <--- Line Search ---> ║ <- Stationarity -> ║ \n",
      "Iter ║ Mu │ Value ║    Objective   ║ Ineq │  Eq  ║ SD │ Evals │     t    ║ Grads │    Value   ║ \n",
      "═════╬════════════╬════════════════╬═════════════╬═══════════════════════╬════════════════════╣\n",
      "   0 ║  - │   -   ║  2.85920658119 ║   -  │   -  ║ -  │     1 │ 0.000000 ║     1 │ 19.48057   ║ \n",
      "   1 ║  - │   -   ║  2.04848541614 ║   -  │   -  ║ QN │     3 │ 0.250000 ║     1 │ 22.65827   ║ \n",
      "   2 ║  - │   -   ║  1.36907603528 ║   -  │   -  ║ QN │     2 │ 0.500000 ║     1 │ 56.16579   ║ \n",
      "   3 ║  - │   -   ║  1.19298203144 ║   -  │   -  ║ QN │     5 │ 0.062500 ║     1 │ 64.27686   ║ \n",
      "   4 ║  - │   -   ║  0.90235679006 ║   -  │   -  ║ QN │    12 │ 4.88e-04 ║     1 │ 3.712494   ║ \n",
      "   5 ║  - │   -   ║  0.81130495418 ║   -  │   -  ║ QN │    10 │ 0.251953 ║     1 │ 8.431358   ║ \n",
      "   6 ║  - │   -   ║  0.70359800349 ║   -  │   -  ║ QN │     8 │ 0.007812 ║     1 │ 0.432637   ║ \n",
      "   7 ║  - │   -   ║  0.62469338554 ║   -  │   -  ║ QN │     8 │ 0.023438 ║     1 │ 0.942076   ║ \n",
      "   8 ║  - │   -   ║  0.54810677630 ║   -  │   -  ║ QN │     8 │ 0.023438 ║     1 │ 2.230167   ║ \n",
      "   9 ║  - │   -   ║  0.53972178666 ║   -  │   -  ║ QN │     6 │ 0.031250 ║     1 │ 3.235593   ║ \n",
      "  10 ║  - │   -   ║  0.53866335936 ║   -  │   -  ║ QN │    21 │ 4.77e-06 ║     1 │ 871.6312   ║ \n",
      "  11 ║  - │   -   ║  0.53808372315 ║   -  │   -  ║ QN │    14 │ 1.22e-04 ║     1 │ 256.4433   ║ \n",
      "  12 ║  - │   -   ║  0.52922956526 ║   -  │   -  ║ QN │    20 │ 1.91e-06 ║     1 │ 784.4861   ║ \n",
      "  13 ║  - │   -   ║  0.52898979526 ║   -  │   -  ║ QN │    20 │ 1.91e-06 ║     1 │ 18589.21   ║ \n",
      "  14 ║  - │   -   ║  0.48601027033 ║   -  │   -  ║ QN │    20 │ 5.72e-06 ║     1 │ 14223.17   ║ \n",
      "  15 ║  - │   -   ║  0.48588665391 ║   -  │   -  ║ QN │    21 │ 2.86e-06 ║     1 │ 267.8673   ║ \n",
      "  16 ║  - │   -   ║  0.46971206828 ║   -  │   -  ║ QN │    30 │ 1.86e-09 ║     1 │ 626576.0   ║ \n",
      "  17 ║  - │   -   ║  0.46758850527 ║   -  │   -  ║ QN │    22 │ 1.43e-06 ║     1 │ 33722.04   ║ \n",
      "  18 ║  - │   -   ║  0.43883030409 ║   -  │   -  ║ QN │    22 │ 4.77e-07 ║     1 │ 29003.75   ║ \n",
      "  19 ║  - │   -   ║  0.43765539867 ║   -  │   -  ║ QN │    17 │ 4.58e-05 ║     1 │ 203.7995   ║ \n",
      "═════╬════════════╬════════════════╬═════════════╬═══════════════════════╬════════════════════╣\n",
      "     ║ Penalty Fn ║                ║  Violation  ║ <--- Line Search ---> ║ <- Stationarity -> ║ \n",
      "Iter ║ Mu │ Value ║    Objective   ║ Ineq │  Eq  ║ SD │ Evals │     t    ║ Grads │    Value   ║ \n",
      "═════╬════════════╬════════════════╬═════════════╬═══════════════════════╬════════════════════╣\n",
      "  20 ║  - │   -   ║  0.42281668940 ║   -  │   -  ║ QN │    15 │ 0.002258 ║     1 │ 102.5399   ║ \n",
      "  21 ║  - │   -   ║  0.42235126441 ║   -  │   -  ║ QN │    28 │ 1.56e-07 ║     1 │ 56753.37   ║ \n",
      "  22 ║  - │   -   ║  0.42233251547 ║   -  │   -  ║ QN │    15 │ 6.10e-05 ║     1 │ 133.9852   ║ \n",
      "  23 ║  - │   -   ║  0.42195470648 ║   -  │   -  ║ QN │    24 │ 1.19e-07 ║     1 │ 506.9870   ║ \n",
      "  24 ║  - │   -   ║  0.39215757557 ║   -  │   -  ║ QN │    20 │ 1.91e-06 ║     1 │ 1795.155   ║ \n",
      "  25 ║  - │   -   ║  0.37812432223 ║   -  │   -  ║ QN │    20 │ 1.91e-06 ║     1 │ 2931.176   ║ \n",
      "  26 ║  - │   -   ║  0.34828570333 ║   -  │   -  ║ QN │    20 │ 1.91e-06 ║     1 │ 207.1068   ║ \n",
      "  27 ║  - │   -   ║  0.31826789773 ║   -  │   -  ║ QN │    22 │ 2.38e-06 ║     1 │ 11143.11   ║ \n",
      "  28 ║  - │   -   ║  0.24769211852 ║   -  │   -  ║ QN │     2 │ 0.500000 ║     1 │ 1.338254   ║ \n",
      "  29 ║  - │   -   ║  0.24417722441 ║   -  │   -  ║ QN │    15 │ 6.10e-05 ║     1 │ 149.7541   ║ \n",
      "  30 ║  - │   -   ║  0.24139139871 ║   -  │   -  ║ QN │    21 │ 9.54e-07 ║     1 │ 1409.352   ║ \n",
      "  31 ║  - │   -   ║  0.24115754042 ║   -  │   -  ║ QN │    20 │ 1.72e-05 ║     1 │ 244.8895   ║ \n",
      "  32 ║  - │   -   ║  0.23041723733 ║   -  │   -  ║ QN │    10 │ 0.005859 ║     1 │ 3.072354   ║ \n",
      "  33 ║  - │   -   ║  0.23040946812 ║   -  │   -  ║ QN │    23 │ 2.38e-07 ║     1 │ 6168.983   ║ \n",
      "  34 ║  - │   -   ║  0.22232741297 ║   -  │   -  ║ QN │    17 │ 1.53e-05 ║     1 │ 3267.766   ║ \n",
      "  35 ║  - │   -   ║  0.22129648664 ║   -  │   -  ║ QN │    17 │ 1.53e-05 ║     1 │ 86.37499   ║ \n",
      "  36 ║  - │   -   ║  0.22080358149 ║   -  │   -  ║ QN │    13 │ 2.44e-04 ║     1 │ 0.764361   ║ \n",
      "  37 ║  - │   -   ║  0.21612266930 ║   -  │   -  ║ QN │    24 │ 1.19e-07 ║     1 │ 3224.509   ║ \n",
      "  38 ║  - │   -   ║  0.21495112222 ║   -  │   -  ║ QN │    23 │ 2.15e-06 ║     1 │ 1052.365   ║ \n",
      "  39 ║  - │   -   ║  0.20662656817 ║   -  │   -  ║ QN │    16 │ 3.05e-05 ║     1 │ 78.02485   ║ \n",
      "═════╬════════════╬════════════════╬═════════════╬═══════════════════════╬════════════════════╣\n",
      "     ║ Penalty Fn ║                ║  Violation  ║ <--- Line Search ---> ║ <- Stationarity -> ║ \n",
      "Iter ║ Mu │ Value ║    Objective   ║ Ineq │  Eq  ║ SD │ Evals │     t    ║ Grads │    Value   ║ \n",
      "═════╬════════════╬════════════════╬═════════════╬═══════════════════════╬════════════════════╣\n",
      "  40 ║  - │   -   ║  0.20559258054 ║   -  │   -  ║ QN │    30 │ 9.31e-09 ║     1 │ 443896.5   ║ \n",
      "  41 ║  - │   -   ║  0.20485409917 ║   -  │   -  ║ QN │    21 │ 4.10e-05 ║     1 │ 2312.242   ║ \n",
      "  42 ║  - │   -   ║  0.18540882712 ║   -  │   -  ║ QN │     6 │ 0.031250 ║     1 │ 1.360578   ║ \n",
      "  43 ║  - │   -   ║  0.18514844691 ║   -  │   -  ║ QN │    15 │ 6.10e-05 ║     1 │ 14.19470   ║ \n",
      "  44 ║  - │   -   ║  0.17464647293 ║   -  │   -  ║ QN │    22 │ 4.77e-07 ║     1 │ 1582.438   ║ \n",
      "  45 ║  - │   -   ║  0.17002108429 ║   -  │   -  ║ QN │    17 │ 1.53e-05 ║     1 │ 1760.440   ║ \n",
      "  46 ║  - │   -   ║  0.16955644432 ║   -  │   -  ║ QN │    20 │ 5.72e-06 ║     1 │ 2520.389   ║ \n",
      "  47 ║  - │   -   ║  0.16156180926 ║   -  │   -  ║ QN │    19 │ 1.14e-05 ║     1 │ 612.7022   ║ \n",
      "  48 ║  - │   -   ║  0.16020670932 ║   -  │   -  ║ QN │    24 │ 1.19e-07 ║     1 │ 76624.84   ║ \n",
      "  49 ║  - │   -   ║  0.15559051094 ║   -  │   -  ║ QN │     4 │ 0.125000 ║     1 │ 6.299294   ║ \n",
      "  50 ║  - │   -   ║  0.15333659661 ║   -  │   -  ║ QN │     9 │ 0.003906 ║     1 │ 0.121282   ║ \n",
      "  51 ║  - │   -   ║  0.15244617341 ║   -  │   -  ║ QN │    16 │ 3.05e-05 ║     1 │ 12.82891   ║ \n",
      "  52 ║  - │   -   ║  0.15165267751 ║   -  │   -  ║ QN │    28 │ 8.20e-08 ║     1 │ 110937.9   ║ \n",
      "  53 ║  - │   -   ║  0.15129620812 ║   -  │   -  ║ QN │    23 │ 1.67e-06 ║     1 │ 2803.725   ║ \n",
      "  54 ║  - │   -   ║  0.14928404587 ║   -  │   -  ║ QN │    23 │ 1.19e-06 ║     1 │ 1056.513   ║ \n",
      "  55 ║  - │   -   ║  0.14855988476 ║   -  │   -  ║ QN │    28 │ 8.20e-08 ║     1 │ 110286.6   ║ \n",
      "  56 ║  - │   -   ║  0.14610563820 ║   -  │   -  ║ QN │     3 │ 0.250000 ║     1 │ 0.206264   ║ \n",
      "  57 ║  - │   -   ║  0.14610097947 ║   -  │   -  ║ QN │    14 │ 1.22e-04 ║     1 │ 0.763167   ║ \n",
      "  58 ║  - │   -   ║  0.14582824285 ║   -  │   -  ║ QN │    29 │ 1.86e-08 ║     1 │ 123387.4   ║ \n",
      "  59 ║  - │   -   ║  0.14569721404 ║   -  │   -  ║ QN │    24 │ 3.58e-07 ║     1 │ 1859.900   ║ \n",
      "═════╬════════════╬════════════════╬═════════════╬═══════════════════════╬════════════════════╣\n",
      "     ║ Penalty Fn ║                ║  Violation  ║ <--- Line Search ---> ║ <- Stationarity -> ║ \n",
      "Iter ║ Mu │ Value ║    Objective   ║ Ineq │  Eq  ║ SD │ Evals │     t    ║ Grads │    Value   ║ \n",
      "═════╬════════════╬════════════════╬═════════════╬═══════════════════════╬════════════════════╣\n",
      "  60 ║  - │   -   ║  0.14566572802 ║   -  │   -  ║ QN │    22 │ 4.77e-07 ║     1 │ 8447.537   ║ \n",
      "  61 ║  - │   -   ║  0.14562387090 ║   -  │   -  ║ QN │    26 │ 2.09e-07 ║     1 │ 20306.24   ║ \n",
      "  62 ║  - │   -   ║  0.14559701086 ║   -  │   -  ║ QN │    28 │ 5.22e-08 ║     1 │ 81297.99   ║ \n",
      "  63 ║  - │   -   ║  0.14517143249 ║   -  │   -  ║ QN │     2 │ 0.500000 ║     1 │ 0.214963   ║ \n",
      "  64 ║  - │   -   ║  0.14516664382 ║   -  │   -  ║ QN │    29 │ 3.73e-09 ║     1 │ 167589.7   ║ \n",
      "  65 ║  - │   -   ║  0.14510600087 ║   -  │   -  ║ QN │    25 │ 8.94e-07 ║     1 │ 436.7653   ║ \n",
      "  66 ║  - │   -   ║  0.14500052170 ║   -  │   -  ║ QN │    27 │ 1.04e-07 ║     1 │ 2665.335   ║ \n",
      "  67 ║  - │   -   ║  0.14487093802 ║   -  │   -  ║ QN │    31 │ 2.79e-09 ║     1 │ 6366.004   ║ \n",
      "  68 ║  - │   -   ║  0.14482265591 ║   -  │   -  ║ QN │    24 │ 1.19e-07 ║     1 │ 9065.683   ║ \n",
      "  69 ║  - │   -   ║  0.14443780884 ║   -  │   -  ║ QN │    28 │ 2.24e-08 ║     1 │ 36463.10   ║ \n",
      "  70 ║  - │   -   ║  0.14433211181 ║   -  │   -  ║ QN │     4 │ 0.125000 ║     1 │ 0.002486   ║ \n",
      "  71 ║  - │   -   ║  0.14433127437 ║   -  │   -  ║ QN │    37 │ 1.46e-11 ║     1 │ 250802.5   ║ \n",
      "  72 ║  - │   -   ║  0.14433081543 ║   -  │   -  ║ QN │    31 │ 6.52e-09 ║     1 │ 427.0600   ║ \n",
      "  73 ║  - │   -   ║  0.14432885148 ║   -  │   -  ║ QN │    31 │ 9.31e-10 ║     1 │ 59855.66   ║ \n",
      "  74 ║  - │   -   ║  0.14432771943 ║   -  │   -  ║ QN │    35 │ 5.82e-11 ║     1 │ 665488.1   ║ \n",
      "  75 ║  - │   -   ║  0.14432771750 ║   -  │   -  ║ QN │    23 │ 2.38e-07 ║     1 │ 15.92396   ║ \n",
      "  76 ║  - │   -   ║  0.14431527642 ║   -  │   -  ║ QN │    32 │ 2.33e-09 ║     1 │ 56481.92   ║ \n",
      "  77 ║  - │   -   ║  0.14430945369 ║   -  │   -  ║ QN │    34 │ 1.16e-10 ║     1 │ 289862.9   ║ \n",
      "  78 ║  - │   -   ║  0.14430883726 ║   -  │   -  ║ QN │    28 │ 7.45e-09 ║     1 │ 531.3751   ║ \n",
      "  79 ║  - │   -   ║  0.14430837708 ║   -  │   -  ║ QN │    32 │ 8.85e-09 ║     1 │ 658.7398   ║ \n",
      "═════╬════════════╬════════════════╬═════════════╬═══════════════════════╬════════════════════╣\n",
      "     ║ Penalty Fn ║                ║  Violation  ║ <--- Line Search ---> ║ <- Stationarity -> ║ \n",
      "Iter ║ Mu │ Value ║    Objective   ║ Ineq │  Eq  ║ SD │ Evals │     t    ║ Grads │    Value   ║ \n",
      "═════╬════════════╬════════════════╬═════════════╬═══════════════════════╬════════════════════╣\n",
      "  80 ║  - │   -   ║  0.14427955129 ║   -  │   -  ║ QN │    26 │ 2.98e-08 ║     1 │ 93324.48   ║ \n",
      "  81 ║  - │   -   ║  0.14427947915 ║   -  │   -  ║ QN │    11 │ 9.77e-04 ║     1 │ 0.056544   ║ \n",
      "  82 ║  - │   -   ║  0.14427882595 ║   -  │   -  ║ QN │    34 │ 1.16e-10 ║     1 │ 308652.8   ║ \n",
      "  83 ║  - │   -   ║  0.14427468918 ║   -  │   -  ║ QN │    31 │ 4.66e-09 ║     1 │ 2054.402   ║ \n",
      "  84 ║  - │   -   ║  0.14427437641 ║   -  │   -  ║ QN │    34 │ 1.16e-10 ║     1 │ 545.9385   ║ \n",
      "  85 ║  - │   -   ║  0.14427434164 ║   -  │   -  ║ QN │    31 │ 9.31e-10 ║     1 │ 533.3197   ║ \n",
      "  86 ║  - │   -   ║  0.14427401710 ║   -  │   -  ║ QN │    38 │ 7.28e-12 ║     1 │ 108730.7   ║ \n",
      "  87 ║  - │   -   ║  0.14427400326 ║   -  │   -  ║ QN │     7 │ 0.015625 ║     1 │ 0.022630   ║ \n",
      "  88 ║  - │   -   ║  0.14427400322 ║   -  │   -  ║ QN │    27 │ 1.49e-08 ║     1 │ 2.674648   ║ \n",
      "  89 ║  - │   -   ║  0.14427384417 ║   -  │   -  ║ QN │    31 │ 2.79e-09 ║     1 │ 280.6216   ║ \n",
      "  90 ║  - │   -   ║  0.14427366695 ║   -  │   -  ║ QN │    35 │ 2.91e-10 ║     1 │ 1825.699   ║ \n",
      "  91 ║  - │   -   ║  0.14427322943 ║   -  │   -  ║ QN │    34 │ 1.16e-10 ║     1 │ 596.6980   ║ \n",
      "  92 ║  - │   -   ║  0.14427311152 ║   -  │   -  ║ QN │    41 │ 8.19e-12 ║     1 │ 58313.99   ║ \n",
      "  93 ║  - │   -   ║  0.14427302703 ║   -  │   -  ║ QN │     4 │ 0.125000 ║     1 │ 0.005456   ║ \n",
      "  94 ║  - │   -   ║  0.14427302672 ║   -  │   -  ║ QN │    14 │ 1.22e-04 ║     1 │ 7.23e-04   ║ \n",
      "  95 ║  - │   -   ║  0.14427300547 ║   -  │   -  ║ QN │    42 │ 4.55e-13 ║     1 │ 659250.6   ║ \n",
      "  96 ║  - │   -   ║  0.14427299536 ║   -  │   -  ║ QN │    37 │ 7.28e-11 ║     1 │ 5166.398   ║ \n",
      "  97 ║  - │   -   ║  0.14427295708 ║   -  │   -  ║ QN │    37 │ 4.37e-11 ║     1 │ 35623.59   ║ \n",
      "  98 ║  - │   -   ║  0.14427295663 ║   -  │   -  ║ QN │    24 │ 1.19e-07 ║     1 │ 4332.994   ║ \n",
      "  99 ║  - │   -   ║  0.14427294491 ║   -  │   -  ║ QN │    40 │ 1.82e-12 ║     1 │ 58252.34   ║ \n",
      "═════╬════════════╬════════════════╬═════════════╬═══════════════════════╬════════════════════╣\n",
      "     ║ Penalty Fn ║                ║  Violation  ║ <--- Line Search ---> ║ <- Stationarity -> ║ \n",
      "Iter ║ Mu │ Value ║    Objective   ║ Ineq │  Eq  ║ SD │ Evals │     t    ║ Grads │    Value   ║ \n",
      "═════╬════════════╬════════════════╬═════════════╬═══════════════════════╬════════════════════╣\n",
      " 100 ║  - │   -   ║  0.14427292510 ║   -  │   -  ║ QN │     9 │ 0.003906 ║     1 │ 0.047070   ║ \n",
      " 101 ║  - │   -   ║  0.14427292349 ║   -  │   -  ║ QN │    43 │ 2.27e-13 ║     2 │ 5.60e-04   ║ \n",
      " 102 ║  - │   -   ║  0.14427292165 ║   -  │   -  ║ QN │    37 │ 1.31e-10 ║     3 │ 1.01e-04   ║ \n",
      " 103 ║  - │   -   ║  0.14427291459 ║   -  │   -  ║ QN │    40 │ 1.27e-11 ║     4 │ 4.16e-05   ║ \n",
      " 104 ║  - │   -   ║  0.14427290777 ║   -  │   -  ║ QN │    44 │ 3.41e-13 ║     5 │ 5.47e-06   ║ \n",
      " 105 ║  - │   -   ║  0.14427290199 ║   -  │   -  ║ QN │    44 │ 3.41e-13 ║     6 │ 0.001056   ║ \n",
      " 106 ║  - │   -   ║  0.14427290134 ║   -  │   -  ║ QN │    48 │ 6.39e-14 ║     7 │ 1.11e-05   ║ \n",
      " 107 ║  - │   -   ║  0.14427289796 ║   -  │   -  ║ QN │     8 │ 0.007812 ║     8 │ 1.62e-06   ║ \n",
      " 108 ║  - │   -   ║  0.14427289439 ║   -  │   -  ║ QN │    41 │ 9.09e-13 ║     9 │ 4.68e-05   ║ \n",
      " 109 ║  - │   -   ║  0.14427289377 ║   -  │   -  ║ QN │    40 │ 2.36e-11 ║    10 │ 1.90e-06   ║ \n",
      " 110 ║  - │   -   ║  0.14427289323 ║   -  │   -  ║ QN │    43 │ 1.59e-12 ║    11 │ 4.76e-06   ║ \n",
      " 111 ║  - │   -   ║  0.14427289228 ║   -  │   -  ║ QN │    18 │ 7.63e-06 ║    12 │ 2.66e-07   ║ \n",
      " 112 ║  - │   -   ║  0.14427289145 ║   -  │   -  ║ QN │    43 │ 2.27e-13 ║    13 │ 6.65e-05   ║ \n",
      " 113 ║  - │   -   ║  0.14427289082 ║   -  │   -  ║ QN │    44 │ 7.96e-13 ║    14 │ 2.37e-06   ║ \n",
      " 114 ║  - │   -   ║  0.14427289049 ║   -  │   -  ║ QN │    15 │ 6.10e-05 ║    15 │ 7.82e-08   ║ \n",
      " 115 ║  - │   -   ║  0.14427289038 ║   -  │   -  ║ QN │    46 │ 8.53e-14 ║    16 │ 0.002605   ║ \n",
      "═════╩════════════╩════════════════╩═════════════╩═══════════════════════╩════════════════════╣\n",
      "Optimization results:                                                                         ║ \n",
      "F = final iterate, B = Best (to tolerance), MF = Most Feasible                                ║ \n",
      "═════╦════════════╦════════════════╦═════════════╦═══════════════════════╦════════════════════╣\n",
      "   F ║    │       ║  0.14427289038 ║   -  │   -  ║    │       │          ║       │            ║ \n",
      "   B ║    │       ║  0.14427288973 ║   -  │   -  ║    │       │          ║       │            ║ \n",
      "═════╩════════════╩════════════════╩═════════════╩═══════════════════════╩════════════════════╣\n",
      "Iterations:              115                                                                  ║ \n",
      "Function evaluations:    2722                                                                 ║ \n",
      "PyGRANSO termination code: 6 --- line search bracketed a minimizer but failed to satisfy      ║ \n",
      "Wolfe conditions.  This may be an indication that approximate stationarity has been attained. ║ \n",
      "══════════════════════════════════════════════════════════════════════════════════════════════╝\n"
     ]
    }
   ],
   "source": [
    "# Deeplifting time!\n",
    "device = torch.device('cpu')\n",
    "model = model.to(device=device, dtype=torch.double)\n",
    "nvar = getNvarTorch(model.parameters())\n",
    "\n",
    "opts = pygransoStruct()\n",
    "\n",
    "# Inital x0\n",
    "x0 = (\n",
    "    torch.nn.utils.parameters_to_vector(model.parameters())\n",
    "    .detach()\n",
    "    .reshape(nvar, 1)\n",
    "    .to(device=device, dtype=torch.double)\n",
    ")\n",
    "\n",
    "# PyGranso options\n",
    "# Increase max number of iterations and let convege to stationarity\n",
    "# Do we see local minima in the PyGranso version\n",
    "# Dual Annealing, SCIP and Deeplifting, PyGranso (showing there are local minima)\n",
    "opts.x0 = x0\n",
    "opts.torch_device = device\n",
    "opts.print_frequency = 1\n",
    "opts.limited_mem_size = 5\n",
    "opts.stat_l2_model = False\n",
    "opts.double_precision = True\n",
    "opts.opt_tol = 1e-10\n",
    "opts.maxit = 1000\n",
    "\n",
    "# Combined function\n",
    "comb_fn = lambda model: deeplifting_svm(model, inputs_X, y)  # noqa\n",
    "\n",
    "# Run the main algorithm\n",
    "soln = pygranso(var_spec=model, combined_fn=comb_fn, user_opts=opts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ad87dcfe-c481-4410-9549-23ad94382cd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.76361801,  1.02693457, -0.63195973,  1.07959785, -6.23665264])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the best weights and let's check training sample fit\n",
    "best_weights = model(None)\n",
    "best_weights = best_weights.mean(axis=0)\n",
    "best_weights = best_weights.detach().cpu().numpy()\n",
    "best_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5afa72dd-0655-4523-9504-9a68b150fba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_X = inputs_X.cpu().numpy()\n",
    "y = y.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e756d269-a50f-46f2-a3c2-2be0772b3cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_predictions = np.dot(best_weights, inputs_X)\n",
    "predictions = np.sign(raw_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "12fbcb14-b737-4d62-a00c-e76be93e726a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "42718a9d-72dc-4fa4-8ec4-375e7b8dc762",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6933333333333334"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bdca5259-0563-4412-8fc3-4d07530a9d61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 1.,  1.,  1.,  1.,  1., -1.,  1.,  1., -1.,  1., -1.,  1.,  1.,\n",
       "         1., -1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1., -1.,  1., -1.,\n",
       "         1.,  1.,  1.,  1.,  1.,  1., -1.,  1.,  1.,  1.,  1., -1., -1.,\n",
       "        -1.,  1.,  1.,  1., -1.,  1.,  1., -1.,  1., -1., -1.,  1., -1.,\n",
       "         1., -1., -1., -1.,  1., -1.,  1.,  1.,  1.,  1., -1., -1.,  1.,\n",
       "         1.,  1.,  1., -1., -1., -1., -1.,  1.,  1.,  1.,  1., -1.,  1.,\n",
       "         1., -1.,  1., -1., -1.,  1.,  1.,  1.,  1., -1.,  1.,  1.,  1.,\n",
       "        -1., -1., -1., -1.,  1.,  1.,  1.,  1.,  1.,  1.,  1., -1., -1.,\n",
       "         1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1., -1.,  1.,\n",
       "         1.,  1.,  1., -1.,  1.,  1., -1.,  1., -1., -1., -1., -1.,  1.,\n",
       "        -1.,  1.,  1., -1.,  1.,  1.,  1.,  1., -1., -1., -1.,  1.,  1.,\n",
       "        -1.,  1.,  1.,  1.,  1.,  1., -1.]),\n",
       " array([-1.,  1.,  1.,  1.,  1., -1.,  1., -1., -1., -1.,  1.,  1., -1.,\n",
       "         1., -1.,  1.,  1.,  1.,  1.,  1.,  1.,  1., -1., -1.,  1.,  1.,\n",
       "         1.,  1.,  1.,  1., -1., -1., -1.,  1., -1.,  1.,  1., -1., -1.,\n",
       "        -1.,  1.,  1.,  1., -1.,  1., -1.,  1.,  1.,  1.,  1., -1., -1.,\n",
       "         1., -1.,  1.,  1.,  1., -1., -1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "         1., -1.,  1.,  1.,  1., -1., -1.,  1.,  1.,  1.,  1., -1.,  1.,\n",
       "         1., -1.,  1.,  1.,  1.,  1.,  1.,  1.,  1., -1.,  1., -1.,  1.,\n",
       "         1., -1., -1.,  1.,  1.,  1., -1.,  1., -1.,  1., -1.,  1.,  1.,\n",
       "         1.,  1., -1., -1.,  1.,  1.,  1., -1.,  1.,  1.,  1., -1.,  1.,\n",
       "         1.,  1., -1., -1.,  1., -1., -1., -1.,  1., -1., -1., -1.,  1.,\n",
       "        -1.,  1.,  1., -1.,  1.,  1.,  1., -1., -1., -1., -1., -1.,  1.,\n",
       "         1., -1.,  1., -1.,  1.,  1.,  1.]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "112b3ff9-711d-40c2-b7c1-f6605abc948b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['setosa', 'versicolor', 'virginica'], dtype='<U10')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris.target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "57b664e1-d260-4be3-b20c-551efdfb845a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ryandevera/.virtualenvs/deeplifing/lib/python3.9/site-packages/threadpoolctl.py:1010: RuntimeWarning: \n",
      "Found Intel OpenMP ('libiomp') and LLVM OpenMP ('libomp') loaded at\n",
      "the same time. Both libraries are known to be incompatible and this\n",
      "can cause random crashes or deadlocks on Linux when loaded in the\n",
      "same Python program.\n",
      "Using threadpoolctl may cause crashes or deadlocks. For more\n",
      "information and possible workarounds, please see\n",
      "    https://github.com/joblib/threadpoolctl/blob/master/multiple_openmp.md\n",
      "\n",
      "  warnings.warn(msg, RuntimeWarning)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "target_names = ['setosa', 'other']\n",
    "# Apply t-SNE to the data\n",
    "tsne = TSNE(n_components=2, random_state=0)\n",
    "X_tsne = tsne.fit_transform(inputs_X.T[:, :-1])\n",
    "\n",
    "# Create a scatter plot\n",
    "# Create a scatter plot using matplotlib\n",
    "colors = ['red', 'blue', 'green']  # Define a color for each class\n",
    "for i in [-1, 1]:\n",
    "    plt.scatter(\n",
    "        X_tsne[predictions == i, 0],\n",
    "        X_tsne[predictions == i, 1],\n",
    "        c=colors[i],\n",
    "        label=target_names[i],\n",
    "        edgecolors='w',\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "57e2e99f-0ec0-4608-a689-69d149cfbf10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn import datasets\n",
    "# from sklearn.svm import SVC\n",
    "# from sklearn.metrics import accuracy_score\n",
    "\n",
    "# # Load the iris dataset\n",
    "# iris = datasets.load_iris()\n",
    "# X = iris.data\n",
    "# y = iris.target\n",
    "\n",
    "# labels = np.zeros(len(y))\n",
    "# labels[y != 0] = -1\n",
    "# labels[y == 0] = 1\n",
    "\n",
    "# # Initialize the Support Vector Machine Classifier\n",
    "# clf = SVC(kernel='linear')\n",
    "\n",
    "# # Fit the model to the training data\n",
    "# clf.fit(X, labels)\n",
    "\n",
    "# # Predict the labels of the test set\n",
    "# y_pred = clf.predict(X)\n",
    "\n",
    "# # Calculate the accuracy of the model\n",
    "# accuracy_score(labels, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c6c03980-0ec1-45e0-b244-2018222cd235",
   "metadata": {},
   "outputs": [],
   "source": [
    "# labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "df9fc342-f0e7-45dc-99b8-fa36fb5f214a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "da54dab0-14dd-4d78-bf1a-78f893a0df92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the learning function\n",
    "def svm(X_struct, inputs_X, labels):\n",
    "    weight_vec = X_struct.w\n",
    "\n",
    "    # Compute SVM objective\n",
    "    denominator = torch.linalg.norm(weight_vec, ord=2)\n",
    "    prod = torch.matmul(weight_vec.T, inputs_X)\n",
    "    numerator = labels * prod\n",
    "    obj = numerator / denominator\n",
    "\n",
    "    # Orig obj\n",
    "    f = torch.amax(-1 * obj)\n",
    "\n",
    "    ce = None\n",
    "    ci = None\n",
    "    return f, ci, ce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "41c03a3b-0a98-4c7b-9170-ab8ce083675d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[33m╔═════ QP SOLVER NOTICE ════════════════════════════════════════════════════════════════════════╗\n",
      "\u001b[0m\u001b[33m║  PyGRANSO requires a quadratic program (QP) solver that has a quadprog-compatible interface,  ║\n",
      "\u001b[0m\u001b[33m║  the default is osqp. Users may provide their own wrapper for the QP solver.                  ║\n",
      "\u001b[0m\u001b[33m║  To disable this notice, set opts.quadprog_info_msg = False                                   ║\n",
      "\u001b[0m\u001b[33m╚═══════════════════════════════════════════════════════════════════════════════════════════════╝\n",
      "\u001b[0m══════════════════════════════════════════════════════════════════════════════════════════════╗\n",
      "PyGRANSO: A PyTorch-enabled port of GRANSO with auto-differentiation                          ║ \n",
      "Version 1.2.0                                                                                 ║ \n",
      "Licensed under the AGPLv3, Copyright (C) 2021-2022 Tim Mitchell and Buyun Liang               ║ \n",
      "══════════════════════════════════════════════════════════════════════════════════════════════╣\n",
      "Problem specifications:                                                                       ║ \n",
      " # of variables                     :   5                                                     ║ \n",
      " # of inequality constraints        :   0                                                     ║ \n",
      " # of equality constraints          :   0                                                     ║ \n",
      "══════════════════════════════════════════════════════════════════════════════════════════════╣\n",
      "\u001b[33mLimited-memory mode enabled with size = 5.                                                   \u001b[0m ║ \n",
      "\u001b[33mNOTE: limited-memory mode is generally NOT                                                   \u001b[0m ║ \n",
      "\u001b[33mrecommended for nonsmooth problems.                                                          \u001b[0m ║ \n",
      "═════╦════════════╦════════════════╦═════════════╦═══════════════════════╦════════════════════╣\n",
      "     ║ Penalty Fn ║                ║  Violation  ║ <--- Line Search ---> ║ <- Stationarity -> ║ \n",
      "Iter ║ Mu │ Value ║    Objective   ║ Ineq │  Eq  ║ SD │ Evals │     t    ║ Grads │    Value   ║ \n",
      "═════╬════════════╬════════════════╬═════════════╬═══════════════════════╬════════════════════╣\n",
      "   0 ║  - │   -   ║  3.47927997105 ║   -  │   -  ║ -  │     1 │ 0.000000 ║     1 │ 4.520376   ║ \n",
      "   1 ║  - │   -   ║  3.41876364366 ║   -  │   -  ║ QN │     3 │ 0.250000 ║     1 │ 2.052294   ║ \n",
      "   2 ║  - │   -   ║  1.88141889839 ║   -  │   -  ║ QN │     2 │ 2.000000 ║     1 │ 0.441438   ║ \n",
      "   3 ║  - │   -   ║  1.46459142421 ║   -  │   -  ║ QN │     1 │ 1.000000 ║     1 │ 0.348703   ║ \n",
      "   4 ║  - │   -   ║  1.19513741476 ║   -  │   -  ║ QN │     1 │ 1.000000 ║     1 │ 0.206601   ║ \n",
      "   5 ║  - │   -   ║  0.94064218965 ║   -  │   -  ║ QN │     1 │ 1.000000 ║     1 │ 0.192391   ║ \n",
      "   6 ║  - │   -   ║  0.88463032716 ║   -  │   -  ║ QN │     1 │ 1.000000 ║     1 │ 0.154949   ║ \n",
      "   7 ║  - │   -   ║  0.72100526739 ║   -  │   -  ║ QN │     3 │ 1.500000 ║     1 │ 0.584553   ║ \n",
      "   8 ║  - │   -   ║  0.62828793524 ║   -  │   -  ║ QN │     1 │ 1.000000 ║     1 │ 0.199536   ║ \n",
      "   9 ║  - │   -   ║  0.59438805189 ║   -  │   -  ║ QN │     1 │ 1.000000 ║     1 │ 0.110760   ║ \n",
      "  10 ║  - │   -   ║  0.53410628201 ║   -  │   -  ║ QN │     2 │ 0.500000 ║     1 │ 0.446307   ║ \n",
      "  11 ║  - │   -   ║  0.52637776815 ║   -  │   -  ║ QN │     2 │ 0.500000 ║     1 │ 0.054397   ║ \n",
      "  12 ║  - │   -   ║  0.49856773764 ║   -  │   -  ║ QN │     2 │ 2.000000 ║     1 │ 0.031492   ║ \n",
      "  13 ║  - │   -   ║  0.48755251713 ║   -  │   -  ║ QN │     1 │ 1.000000 ║     1 │ 0.106628   ║ \n",
      "  14 ║  - │   -   ║  0.47512449865 ║   -  │   -  ║ QN │     2 │ 0.500000 ║     1 │ 0.125443   ║ \n",
      "  15 ║  - │   -   ║  0.18370369971 ║   -  │   -  ║ QN │     1 │ 1.000000 ║     1 │ 0.357829   ║ \n",
      "  16 ║  - │   -   ║  0.16187576300 ║   -  │   -  ║ QN │     4 │ 8.000000 ║     1 │ 0.379287   ║ \n",
      "  17 ║  - │   -   ║  0.15769510935 ║   -  │   -  ║ QN │     1 │ 1.000000 ║     1 │ 1.132407   ║ \n",
      "  18 ║  - │   -   ║  0.15290140728 ║   -  │   -  ║ QN │     1 │ 1.000000 ║     1 │ 0.544549   ║ \n",
      "  19 ║  - │   -   ║  0.14991437085 ║   -  │   -  ║ QN │     4 │ 0.125000 ║     1 │ 1.299533   ║ \n",
      "═════╬════════════╬════════════════╬═════════════╬═══════════════════════╬════════════════════╣\n",
      "     ║ Penalty Fn ║                ║  Violation  ║ <--- Line Search ---> ║ <- Stationarity -> ║ \n",
      "Iter ║ Mu │ Value ║    Objective   ║ Ineq │  Eq  ║ SD │ Evals │     t    ║ Grads │    Value   ║ \n",
      "═════╬════════════╬════════════════╬═════════════╬═══════════════════════╬════════════════════╣\n",
      "  20 ║  - │   -   ║  0.14558659171 ║   -  │   -  ║ QN │     4 │ 0.375000 ║     1 │ 2.968388   ║ \n",
      "  21 ║  - │   -   ║  0.14539415461 ║   -  │   -  ║ QN │     7 │ 0.046875 ║     1 │ 0.710749   ║ \n",
      "  22 ║  - │   -   ║  0.14525351638 ║   -  │   -  ║ QN │     2 │ 0.500000 ║     1 │ 0.107521   ║ \n",
      "  23 ║  - │   -   ║  0.14520052975 ║   -  │   -  ║ QN │     5 │ 0.062500 ║     1 │ 0.021309   ║ \n",
      "  24 ║  - │   -   ║  0.14484493905 ║   -  │   -  ║ QN │     5 │ 0.062500 ║     1 │ 0.122017   ║ \n",
      "  25 ║  - │   -   ║  0.14481348828 ║   -  │   -  ║ QN │     3 │ 0.250000 ║     1 │ 0.006105   ║ \n",
      "  26 ║  - │   -   ║  0.14478248828 ║   -  │   -  ║ QN │     1 │ 1.000000 ║     1 │ 0.002791   ║ \n",
      "  27 ║  - │   -   ║  0.14475134579 ║   -  │   -  ║ QN │     8 │ 0.039062 ║     1 │ 1.745691   ║ \n",
      "  28 ║  - │   -   ║  0.14472815684 ║   -  │   -  ║ QN │     2 │ 0.500000 ║     1 │ 0.011283   ║ \n",
      "  29 ║  - │   -   ║  0.14472466858 ║   -  │   -  ║ QN │     9 │ 0.003906 ║     1 │ 0.586893   ║ \n",
      "  30 ║  - │   -   ║  0.14446494349 ║   -  │   -  ║ QN │     4 │ 8.000000 ║     1 │ 0.005174   ║ \n",
      "  31 ║  - │   -   ║  0.14442313098 ║   -  │   -  ║ QN │     4 │ 0.375000 ║     1 │ 1.660948   ║ \n",
      "  32 ║  - │   -   ║  0.14437823825 ║   -  │   -  ║ QN │     9 │ 0.003906 ║     1 │ 0.521113   ║ \n",
      "  33 ║  - │   -   ║  0.14435076389 ║   -  │   -  ║ QN │     6 │ 0.031250 ║     1 │ 0.031352   ║ \n",
      "  34 ║  - │   -   ║  0.14432658533 ║   -  │   -  ║ QN │    11 │ 9.77e-04 ║     1 │ 0.597005   ║ \n",
      "  35 ║  - │   -   ║  0.14431895827 ║   -  │   -  ║ QN │    13 │ 0.001221 ║     1 │ 6.780547   ║ \n",
      "  36 ║  - │   -   ║  0.14431646534 ║   -  │   -  ║ QN │     2 │ 0.500000 ║     1 │ 0.001519   ║ \n",
      "  37 ║  - │   -   ║  0.14431632449 ║   -  │   -  ║ QN │     1 │ 1.000000 ║     1 │ 8.17e-04   ║ \n",
      "  38 ║  - │   -   ║  0.14431469861 ║   -  │   -  ║ QN │     5 │ 0.312500 ║     1 │ 0.076473   ║ \n",
      "  39 ║  - │   -   ║  0.14430594857 ║   -  │   -  ║ QN │     5 │ 0.062500 ║     1 │ 0.015969   ║ \n",
      "═════╬════════════╬════════════════╬═════════════╬═══════════════════════╬════════════════════╣\n",
      "     ║ Penalty Fn ║                ║  Violation  ║ <--- Line Search ---> ║ <- Stationarity -> ║ \n",
      "Iter ║ Mu │ Value ║    Objective   ║ Ineq │  Eq  ║ SD │ Evals │     t    ║ Grads │    Value   ║ \n",
      "═════╬════════════╬════════════════╬═════════════╬═══════════════════════╬════════════════════╣\n",
      "  40 ║  - │   -   ║  0.14429188902 ║   -  │   -  ║ QN │    12 │ 0.001465 ║     1 │ 4.056226   ║ \n",
      "  41 ║  - │   -   ║  0.14428217188 ║   -  │   -  ║ QN │     3 │ 0.250000 ║     1 │ 0.046314   ║ \n",
      "  42 ║  - │   -   ║  0.14428187162 ║   -  │   -  ║ QN │     7 │ 0.015625 ║     2 │ 6.04e-05   ║ \n",
      "  43 ║  - │   -   ║  0.14427992671 ║   -  │   -  ║ QN │    10 │ 0.025391 ║     1 │ 1.191513   ║ \n",
      "  44 ║  - │   -   ║  0.14427991235 ║   -  │   -  ║ QN │     1 │ 1.000000 ║     1 │ 7.36e-05   ║ \n",
      "  45 ║  - │   -   ║  0.14427824785 ║   -  │   -  ║ QN │    14 │ 1.22e-04 ║     1 │ 39.07244   ║ \n",
      "  46 ║  - │   -   ║  0.14427796973 ║   -  │   -  ║ QN │     8 │ 0.007812 ║     1 │ 6.284630   ║ \n",
      "  47 ║  - │   -   ║  0.14427771300 ║   -  │   -  ║ QN │    10 │ 0.001953 ║     1 │ 0.562216   ║ \n",
      "  48 ║  - │   -   ║  0.14427769219 ║   -  │   -  ║ QN │    20 │ 1.91e-06 ║     2 │ 8.50e-04   ║ \n",
      "  49 ║  - │   -   ║  0.14427765367 ║   -  │   -  ║ QN │     4 │ 0.125000 ║     1 │ 0.001988   ║ \n",
      "  50 ║  - │   -   ║  0.14427617116 ║   -  │   -  ║ QN │    14 │ 0.001099 ║     1 │ 5.359486   ║ \n",
      "  51 ║  - │   -   ║  0.14427539624 ║   -  │   -  ║ QN │    16 │ 2.75e-04 ║     1 │ 18.11378   ║ \n",
      "  52 ║  - │   -   ║  0.14427487488 ║   -  │   -  ║ QN │     3 │ 0.250000 ║     1 │ 0.009901   ║ \n",
      "  53 ║  - │   -   ║  0.14427478825 ║   -  │   -  ║ QN │    10 │ 0.005859 ║     1 │ 2.824734   ║ \n",
      "  54 ║  - │   -   ║  0.14427474470 ║   -  │   -  ║ QN │    20 │ 1.91e-06 ║     2 │ 4.52e-05   ║ \n",
      "  55 ║  - │   -   ║  0.14427467750 ║   -  │   -  ║ QN │    16 │ 3.05e-05 ║     3 │ 4.56e-05   ║ \n",
      "  56 ║  - │   -   ║  0.14427443085 ║   -  │   -  ║ QN │     6 │ 0.468750 ║     1 │ 0.002004   ║ \n",
      "  57 ║  - │   -   ║  0.14427374351 ║   -  │   -  ║ QN │     2 │ 0.500000 ║     1 │ 8.01e-05   ║ \n",
      "  58 ║  - │   -   ║  0.14427371279 ║   -  │   -  ║ QN │    17 │ 4.58e-05 ║     2 │ 3.96e-06   ║ \n",
      "  59 ║  - │   -   ║  0.14427359823 ║   -  │   -  ║ QN │     1 │ 1.000000 ║     2 │ 4.46e-06   ║ \n",
      "═════╬════════════╬════════════════╬═════════════╬═══════════════════════╬════════════════════╣\n",
      "     ║ Penalty Fn ║                ║  Violation  ║ <--- Line Search ---> ║ <- Stationarity -> ║ \n",
      "Iter ║ Mu │ Value ║    Objective   ║ Ineq │  Eq  ║ SD │ Evals │     t    ║ Grads │    Value   ║ \n",
      "═════╬════════════╬════════════════╬═════════════╬═══════════════════════╬════════════════════╣\n",
      "  60 ║  - │   -   ║  0.14427359773 ║   -  │   -  ║ QN │    28 │ 5.22e-08 ║     3 │ 4.98e-06   ║ \n",
      "  61 ║  - │   -   ║  0.14427351651 ║   -  │   -  ║ QN │    20 │ 9.54e-06 ║     4 │ 3.66e-06   ║ \n",
      "  62 ║  - │   -   ║  0.14427350322 ║   -  │   -  ║ QN │     1 │ 1.000000 ║     5 │ 3.66e-06   ║ \n",
      "  63 ║  - │   -   ║  0.14427341039 ║   -  │   -  ║ QN │    19 │ 7.25e-05 ║     5 │ 5.21e-06   ║ \n",
      "  64 ║  - │   -   ║  0.14427333043 ║   -  │   -  ║ QN │     2 │ 0.500000 ║     6 │ 5.20e-06   ║ \n",
      "  65 ║  - │   -   ║  0.14427321908 ║   -  │   -  ║ QN │    19 │ 2.67e-05 ║     3 │ 3.24e-07   ║ \n",
      "  66 ║  - │   -   ║  0.14427321248 ║   -  │   -  ║ QN │    23 │ 1.67e-06 ║     4 │ 2.98e-07   ║ \n",
      "  67 ║  - │   -   ║  0.14427314997 ║   -  │   -  ║ QN │     3 │ 0.250000 ║     5 │ 2.98e-07   ║ \n",
      "  68 ║  - │   -   ║  0.14427308452 ║   -  │   -  ║ QN │    19 │ 3.81e-06 ║     6 │ 6.39e-09   ║ \n",
      "  69 ║  - │   -   ║  0.14427307476 ║   -  │   -  ║ QN │     2 │ 0.500000 ║     7 │ 5.97e-09   ║ \n",
      "  70 ║  - │   -   ║  0.14427300630 ║   -  │   -  ║ QN │    20 │ 2.86e-05 ║     8 │ 6.46e-09   ║ \n",
      "  71 ║  - │   -   ║  0.14427300626 ║   -  │   -  ║ QN │    12 │ 4.88e-04 ║     9 │ 6.56e-09   ║ \n",
      "  72 ║  - │   -   ║  0.14427299487 ║   -  │   -  ║ QN │     3 │ 0.250000 ║     9 │ 7.21e-09   ║ \n",
      "  73 ║  - │   -   ║  0.14427297606 ║   -  │   -  ║ QN │    23 │ 2.15e-06 ║    10 │ 6.44e-09   ║ \n",
      "  74 ║  - │   -   ║  0.14427297055 ║   -  │   -  ║ QN │     1 │ 1.000000 ║    10 │ 8.03e-09   ║ \n",
      "  75 ║  - │   -   ║  0.14427296142 ║   -  │   -  ║ QN │    21 │ 9.54e-07 ║    10 │ 5.45e-09   ║ \n",
      "  76 ║  - │   -   ║  0.14427296138 ║   -  │   -  ║ QN │    17 │ 1.37e-04 ║    10 │ 3.43e-09   ║ \n",
      "  77 ║  - │   -   ║  0.14427296071 ║   -  │   -  ║ QN │     1 │ 1.000000 ║    10 │ 4.45e-08   ║ \n",
      "  78 ║  - │   -   ║  0.14427294727 ║   -  │   -  ║ QN │    23 │ 2.15e-06 ║    10 │ 4.90e-08   ║ \n",
      "  79 ║  - │   -   ║  0.14427294664 ║   -  │   -  ║ QN │     1 │ 1.000000 ║    10 │ 1.06e-07   ║ \n",
      "═════╬════════════╬════════════════╬═════════════╬═══════════════════════╬════════════════════╣\n",
      "     ║ Penalty Fn ║                ║  Violation  ║ <--- Line Search ---> ║ <- Stationarity -> ║ \n",
      "Iter ║ Mu │ Value ║    Objective   ║ Ineq │  Eq  ║ SD │ Evals │     t    ║ Grads │    Value   ║ \n",
      "═════╬════════════╬════════════════╬═════════════╬═══════════════════════╬════════════════════╣\n",
      "  80 ║  - │   -   ║  0.14427293911 ║   -  │   -  ║ QN │    22 │ 1.43e-06 ║    10 │ 5.85e-08   ║ \n",
      "  81 ║  - │   -   ║  0.14427293680 ║   -  │   -  ║ QN │    21 │ 9.54e-07 ║    10 │ 3.27e-09   ║ \n",
      "  82 ║  - │   -   ║  0.14427293426 ║   -  │   -  ║ QN │     2 │ 0.500000 ║    10 │ 8.72e-08   ║ \n",
      "  83 ║  - │   -   ║  0.14427292990 ║   -  │   -  ║ QN │    23 │ 4.05e-06 ║    10 │ 5.42e-08   ║ \n",
      "  84 ║  - │   -   ║  0.14427292373 ║   -  │   -  ║ QN │     1 │ 1.000000 ║    10 │ 7.10e-08   ║ \n",
      "  85 ║  - │   -   ║  0.14427292122 ║   -  │   -  ║ QN │    23 │ 1.67e-06 ║    10 │ 4.23e-09   ║ \n",
      "  86 ║  - │   -   ║  0.14427291842 ║   -  │   -  ║ QN │    21 │ 2.86e-06 ║    10 │ 2.80e-08   ║ \n",
      "  87 ║  - │   -   ║  0.14427291635 ║   -  │   -  ║ QN │     2 │ 0.500000 ║    10 │ 4.03e-07   ║ \n",
      "  88 ║  - │   -   ║  0.14427291551 ║   -  │   -  ║ QN │    25 │ 1.79e-07 ║    10 │ 2.77e-07   ║ \n",
      "  89 ║  - │   -   ║  0.14427291067 ║   -  │   -  ║ QN │     1 │ 1.000000 ║    10 │ 2.32e-07   ║ \n",
      "  90 ║  - │   -   ║  0.14427290768 ║   -  │   -  ║ QN │    22 │ 3.34e-06 ║    10 │ 1.47e-07   ║ \n",
      "  91 ║  - │   -   ║  0.14427290636 ║   -  │   -  ║ QN │    19 │ 1.14e-05 ║    10 │ 2.54e-07   ║ \n",
      "  92 ║  - │   -   ║  0.14427290100 ║   -  │   -  ║ QN │     3 │ 0.250000 ║     2 │ 2.48e-05   ║ \n",
      "  93 ║  - │   -   ║  0.14427289898 ║   -  │   -  ║ QN │    26 │ 3.28e-07 ║     2 │ 1.41e-05   ║ \n",
      "  94 ║  - │   -   ║  0.14427289774 ║   -  │   -  ║ QN │    21 │ 9.54e-07 ║     3 │ 1.39e-07   ║ \n",
      "  95 ║  - │   -   ║  0.14427289675 ║   -  │   -  ║ QN │    24 │ 1.19e-07 ║     4 │ 4.37e-07   ║ \n",
      "  96 ║  - │   -   ║  0.14427289550 ║   -  │   -  ║ QN │    21 │ 1.43e-05 ║     5 │ 3.47e-07   ║ \n",
      "  97 ║  - │   -   ║  0.14427289479 ║   -  │   -  ║ QN │     2 │ 0.500000 ║     6 │ 1.32e-07   ║ \n",
      "  98 ║  - │   -   ║  0.14427289344 ║   -  │   -  ║ QN │    26 │ 3.28e-07 ║     7 │ 1.63e-08   ║ \n",
      "  99 ║  - │   -   ║  0.14427289256 ║   -  │   -  ║ QN │     2 │ 0.500000 ║     7 │ 1.37e-04   ║ \n",
      "═════╬════════════╬════════════════╬═════════════╬═══════════════════════╬════════════════════╣\n",
      "     ║ Penalty Fn ║                ║  Violation  ║ <--- Line Search ---> ║ <- Stationarity -> ║ \n",
      "Iter ║ Mu │ Value ║    Objective   ║ Ineq │  Eq  ║ SD │ Evals │     t    ║ Grads │    Value   ║ \n",
      "═════╬════════════╬════════════════╬═════════════╬═══════════════════════╬════════════════════╣\n",
      " 100 ║  - │   -   ║  0.14427289216 ║   -  │   -  ║ QN │    25 │ 5.96e-08 ║     8 │ 1.40e-07   ║ \n",
      " 101 ║  - │   -   ║  0.14427289184 ║   -  │   -  ║ QN │    26 │ 2.98e-08 ║     9 │ 7.40e-09   ║ \n",
      " 102 ║  - │   -   ║  0.14427289154 ║   -  │   -  ║ QN │     6 │ 0.156250 ║    10 │ 2.12e-07   ║ \n",
      " 103 ║  - │   -   ║  0.14427289050 ║   -  │   -  ║ QN │    25 │ 2.98e-07 ║    10 │ 9.51e-07   ║ \n",
      " 104 ║  - │   -   ║  0.14427289028 ║   -  │   -  ║ QN │    20 │ 1.91e-06 ║    10 │ 4.91e-08   ║ \n",
      " 105 ║  - │   -   ║  0.14427289021 ║   -  │   -  ║ QN │     3 │ 0.250000 ║     7 │ 1.46e-04   ║ \n",
      " 106 ║  - │   -   ║  0.14427289016 ║   -  │   -  ║ QN │    27 │ 7.45e-08 ║     8 │ 1.49e-07   ║ \n",
      " 107 ║  - │   -   ║  0.14427289005 ║   -  │   -  ║ QN │    18 │ 7.63e-06 ║     9 │ 1.11e-07   ║ \n",
      " 108 ║  - │   -   ║  0.14427288972 ║   -  │   -  ║ QN │    23 │ 2.38e-07 ║    10 │ 4.38e-11   ║ \n",
      "═════╩════════════╩════════════════╩═════════════╩═══════════════════════╩════════════════════╣\n",
      "Optimization results:                                                                         ║ \n",
      "F = final iterate, B = Best (to tolerance), MF = Most Feasible                                ║ \n",
      "═════╦════════════╦════════════════╦═════════════╦═══════════════════════╦════════════════════╣\n",
      "   F ║    │       ║  0.14427288972 ║   -  │   -  ║    │       │          ║       │            ║ \n",
      "   B ║    │       ║  0.14427288972 ║   -  │   -  ║    │       │          ║       │            ║ \n",
      "═════╩════════════╩════════════════╩═════════════╩═══════════════════════╩════════════════════╣\n",
      "Iterations:              108                                                                  ║ \n",
      "Function evaluations:    1073                                                                 ║ \n",
      "PyGRANSO termination code: 0 --- converged to stationarity tolerance.                         ║ \n",
      "══════════════════════════════════════════════════════════════════════════════════════════════╝\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "iris = load_iris()\n",
    "\n",
    "# The data and target labels\n",
    "data = iris.data\n",
    "labels = iris.target\n",
    "\n",
    "# If you want the feature names and target names:\n",
    "feature_names = iris.feature_names\n",
    "target_names = iris.target_names\n",
    "\n",
    "df = pd.DataFrame(data=iris.data, columns=['f1', 'f2', 'f3', 'f4'])\n",
    "df['f5'] = 1.0\n",
    "df['target'] = iris.target\n",
    "\n",
    "df = df.sample(frac=1.0).reset_index(drop=True)\n",
    "\n",
    "# Dimensions\n",
    "output_size = len(feature_names) + 1\n",
    "\n",
    "# Inputs\n",
    "inputs_X = df[['f1', 'f2', 'f3', 'f4', 'f5']].values\n",
    "inputs_X = torch.from_numpy(inputs_X).to(device=device, dtype=torch.double).T\n",
    "\n",
    "# Just two classes for now\n",
    "labels = df['target'].values\n",
    "\n",
    "y = np.zeros(len(labels))\n",
    "y[labels != 1] = 1\n",
    "y[labels == 1] = -1\n",
    "y = torch.from_numpy(y).to(device=device, dtype=torch.double)\n",
    "\n",
    "# Deeplifting time!\n",
    "device = torch.device('cpu')\n",
    "\n",
    "w0 = torch.randn(\n",
    "    (5, 1),\n",
    ").to(device, dtype=torch.double)\n",
    "var_in = {\"w\": list(w0.shape)}\n",
    "\n",
    "comb_fn = lambda X_struct: svm(\n",
    "    X_struct,\n",
    "    inputs_X,\n",
    "    y,\n",
    ")\n",
    "\n",
    "opts = pygransoStruct()\n",
    "\n",
    "# PyGranso options\n",
    "# Increase max number of iterations and let convege to stationarity\n",
    "# Do we see local minima in the PyGranso version\n",
    "# Dual Annealing, SCIP and Deeplifting, PyGranso (showing there are local minima)\n",
    "opts.x0 = torch.reshape(w0, (-1, 1))\n",
    "opts.torch_device = device\n",
    "opts.print_frequency = 1\n",
    "opts.limited_mem_size = 5\n",
    "opts.stat_l2_model = False\n",
    "opts.double_precision = True\n",
    "opts.opt_tol = 1e-10\n",
    "opts.maxit = 1000\n",
    "\n",
    "# Run the main algorithm\n",
    "soln = pygranso(var_spec=var_in, combined_fn=comb_fn, user_opts=opts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bf332e6c-d183-4fd5-bc91-8591c380dfd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_weights = soln.best.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6b0838ad-47fb-46c1-8021-6eb539a97b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_predictions = np.dot(best_weights.T, inputs_X)\n",
    "predictions = np.sign(raw_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7df054d4-3230-4435-a7c1-43994ab249dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6933333333333334"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y.numpy().flatten(), predictions.flatten())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f0f91aa-1595-40de-8cde-8fed0b3a6b53",
   "metadata": {},
   "source": [
    "# Let's Try MNIST\n",
    "\n",
    "MNIST is a larger dataset with more \"features\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6da8b1af-4599-4764-b128-eb7f8b9e810a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import metrics\n",
    "from scipy.optimize import differential_evolution, dual_annealing\n",
    "\n",
    "# Load the MNIST dataset\n",
    "digits = datasets.load_digits()\n",
    "\n",
    "# Split the dataset into features and target variable\n",
    "X = digits.data / 255.0\n",
    "y = digits.target\n",
    "\n",
    "labels = np.zeros(len(y))\n",
    "labels[y == 0] = 1\n",
    "labels[y != 0] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3d62bb1e-3716-40ff-99d6-44daa165b468",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 1797)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dual annealing and differential evolution\n",
    "inputs_X = X.T.copy()\n",
    "inputs_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "aaa972cc-7e3f-4100-94b7-994abc65476e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the learning function\n",
    "def svm(weight_vec, inputs_X, labels):\n",
    "    # Compute SVM objective\n",
    "    denominator = np.linalg.norm(weight_vec, ord=2)\n",
    "    prod = np.matmul(weight_vec.T, inputs_X)\n",
    "\n",
    "    numerator = (labels * prod).flatten()\n",
    "    obj = numerator / denominator\n",
    "\n",
    "    # Orig obj\n",
    "    f = np.amax(-1 * obj)\n",
    "    return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fcb9c8dd-9a06-4347-871c-393a629f44d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a weight vector\n",
    "x0 = np.random.randn(inputs_X.shape[0])\n",
    "\n",
    "fn = lambda w: svm(w, inputs_X, labels)\n",
    "bounds = [(-10, 10)] * inputs_X.shape[0]\n",
    "\n",
    "result = dual_annealing(\n",
    "    fn,\n",
    "    bounds,\n",
    "    x0=x0,\n",
    "    maxiter=10000,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5b0f8082-fb2a-4367-8668-c0e2b633c7fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " message: ['Maximum number of iteration reached']\n",
       " success: True\n",
       "  status: 0\n",
       "     fun: -0.006855065604229168\n",
       "       x: [ 2.250e-01 -1.236e+00 ... -6.860e+00 -2.767e+00]\n",
       "     nit: 10000\n",
       "    nfev: 2013924\n",
       "    njev: 11291\n",
       "    nhev: 0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f333fc30-6cf2-4591-95ff-9731634da1ad",
   "metadata": {},
   "source": [
    "# PyGRANSO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b92e114e-f1b2-475f-89f6-35887299929e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "# Set up the learning function\n",
    "def svm(X_struct, inputs_X, labels):\n",
    "    weight_vec = X_struct.w\n",
    "\n",
    "    # Compute SVM objective\n",
    "    denominator = torch.linalg.norm(weight_vec, ord=2)\n",
    "    prod = torch.matmul(weight_vec.T, inputs_X)\n",
    "    numerator = labels * prod\n",
    "    obj = numerator / denominator\n",
    "\n",
    "    # Orig obj\n",
    "    f = torch.amax(-1 * obj)\n",
    "\n",
    "    ce = None\n",
    "    ci = None\n",
    "    return f, ci, ce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0fb31d05-5e94-46d3-8d16-2f03c0a46a8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 1797)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8e19a8e8-3d84-432c-955d-13a070304861",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 1.        , 1.        , ..., 1.        , 1.        ,\n",
       "        1.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.        , 0.03921569, 0.0627451 , ..., 0.02352941, 0.04705882,\n",
       "        0.04705882],\n",
       "       [0.        , 0.        , 0.03529412, ..., 0.        , 0.        ,\n",
       "        0.00392157],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs_X = np.vstack([np.ones(inputs_X.shape[1]), inputs_X])\n",
    "inputs_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1d2d96c8-c3da-4a82-8dd5-ea62d3f6237b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(65, 1797)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5b3e36b8-ec1e-449c-8418-40fb366f6bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pygranso functions\n",
    "from pygranso.private.getNvar import getNvarTorch\n",
    "from pygranso.pygranso import pygranso\n",
    "from pygranso.pygransoStruct import pygransoStruct\n",
    "\n",
    "# Deeplifting time!\n",
    "device = torch.device('cpu')\n",
    "\n",
    "# Inputs\n",
    "inputs_X = torch.from_numpy(inputs_X).to(device=device, dtype=torch.double)\n",
    "labels = torch.from_numpy(labels).to(device=device, dtype=torch.double)\n",
    "\n",
    "\n",
    "w0 = torch.randn(\n",
    "    (65, 1),\n",
    ").to(device, dtype=torch.double)\n",
    "var_in = {\"w\": list(w0.shape)}\n",
    "\n",
    "comb_fn = lambda X_struct: svm(\n",
    "    X_struct,\n",
    "    inputs_X,\n",
    "    labels,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ac5fb42d-81e8-4a66-a310-920529a05ca3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[33m╔═════ QP SOLVER NOTICE ════════════════════════════════════════════════════════════════════════╗\n",
      "\u001b[0m\u001b[33m║  PyGRANSO requires a quadratic program (QP) solver that has a quadprog-compatible interface,  ║\n",
      "\u001b[0m\u001b[33m║  the default is osqp. Users may provide their own wrapper for the QP solver.                  ║\n",
      "\u001b[0m\u001b[33m║  To disable this notice, set opts.quadprog_info_msg = False                                   ║\n",
      "\u001b[0m\u001b[33m╚═══════════════════════════════════════════════════════════════════════════════════════════════╝\n",
      "\u001b[0m══════════════════════════════════════════════════════════════════════════════════════════════╗\n",
      "PyGRANSO: A PyTorch-enabled port of GRANSO with auto-differentiation                          ║ \n",
      "Version 1.2.0                                                                                 ║ \n",
      "Licensed under the AGPLv3, Copyright (C) 2021-2022 Tim Mitchell and Buyun Liang               ║ \n",
      "══════════════════════════════════════════════════════════════════════════════════════════════╣\n",
      "Problem specifications:                                                                       ║ \n",
      " # of variables                     :   65                                                    ║ \n",
      " # of inequality constraints        :    0                                                    ║ \n",
      " # of equality constraints          :    0                                                    ║ \n",
      "══════════════════════════════════════════════════════════════════════════════════════════════╣\n",
      "\u001b[33mLimited-memory mode enabled with size = 5.                                                   \u001b[0m ║ \n",
      "\u001b[33mNOTE: limited-memory mode is generally NOT                                                   \u001b[0m ║ \n",
      "\u001b[33mrecommended for nonsmooth problems.                                                          \u001b[0m ║ \n",
      "═════╦════════════╦════════════════╦═════════════╦═══════════════════════╦════════════════════╣\n",
      "     ║ Penalty Fn ║                ║  Violation  ║ <--- Line Search ---> ║ <- Stationarity -> ║ \n",
      "Iter ║ Mu │ Value ║    Objective   ║ Ineq │  Eq  ║ SD │ Evals │     t    ║ Grads │    Value   ║ \n",
      "═════╬════════════╬════════════════╬═════════════╬═══════════════════════╬════════════════════╣\n",
      "   0 ║  - │   -   ║  0.05209001023 ║   -  │   -  ║ -  │     1 │ 0.000000 ║     1 │ 0.114292   ║ \n",
      "  10 ║  - │   -   ║  0.02152807473 ║   -  │   -  ║ QN │     1 │ 1.000000 ║     1 │ 0.043700   ║ \n",
      "  20 ║  - │   -   ║  0.01116405073 ║   -  │   -  ║ QN │     1 │ 1.000000 ║     1 │ 0.030978   ║ \n",
      "  30 ║  - │   -   ║  0.00724813175 ║   -  │   -  ║ QN │     3 │ 0.250000 ║     1 │ 0.588170   ║ \n",
      "  40 ║  - │   -   ║  0.00526713544 ║   -  │   -  ║ QN │     2 │ 2.000000 ║     1 │ 0.022110   ║ \n",
      "  50 ║  - │   -   ║  0.00457209458 ║   -  │   -  ║ QN │     8 │ 0.007812 ║     1 │ 0.385900   ║ \n",
      "  60 ║  - │   -   ║  0.00299700039 ║   -  │   -  ║ QN │     1 │ 1.000000 ║     1 │ 0.016541   ║ \n",
      "  70 ║  - │   -   ║  0.00113449592 ║   -  │   -  ║ QN │     1 │ 1.000000 ║     1 │ 0.027146   ║ \n",
      "  80 ║  - │   -   ║ -1.9736853e-04 ║   -  │   -  ║ QN │     2 │ 0.500000 ║     1 │ 0.035090   ║ \n",
      "  90 ║  - │   -   ║ -6.2690808e-04 ║   -  │   -  ║ QN │     2 │ 0.500000 ║     1 │ 0.021352   ║ \n",
      " 100 ║  - │   -   ║ -0.00157592812 ║   -  │   -  ║ QN │     3 │ 4.000000 ║     1 │ 0.036819   ║ \n",
      " 110 ║  - │   -   ║ -0.00198153940 ║   -  │   -  ║ QN │     2 │ 0.500000 ║     1 │ 0.040335   ║ \n",
      " 120 ║  - │   -   ║ -0.00216198431 ║   -  │   -  ║ QN │     1 │ 1.000000 ║     1 │ 0.021526   ║ \n",
      " 130 ║  - │   -   ║ -0.00231811835 ║   -  │   -  ║ QN │     9 │ 0.003906 ║     1 │ 1.367204   ║ \n",
      " 140 ║  - │   -   ║ -0.00232875292 ║   -  │   -  ║ QN │    14 │ 6.10e-04 ║     1 │ 3.089211   ║ \n",
      " 150 ║  - │   -   ║ -0.00234485935 ║   -  │   -  ║ QN │     8 │ 0.007812 ║     1 │ 0.224321   ║ \n",
      " 160 ║  - │   -   ║ -0.00255025487 ║   -  │   -  ║ QN │    13 │ 2.44e-04 ║     1 │ 0.229879   ║ \n",
      " 170 ║  - │   -   ║ -0.00263167424 ║   -  │   -  ║ QN │     4 │ 0.125000 ║     1 │ 0.804669   ║ \n",
      " 180 ║  - │   -   ║ -0.00281801364 ║   -  │   -  ║ QN │    11 │ 9.77e-04 ║     1 │ 0.625941   ║ \n",
      " 190 ║  - │   -   ║ -0.00411820745 ║   -  │   -  ║ QN │     3 │ 0.250000 ║     1 │ 0.098217   ║ \n",
      "═════╬════════════╬════════════════╬═════════════╬═══════════════════════╬════════════════════╣\n",
      "     ║ Penalty Fn ║                ║  Violation  ║ <--- Line Search ---> ║ <- Stationarity -> ║ \n",
      "Iter ║ Mu │ Value ║    Objective   ║ Ineq │  Eq  ║ SD │ Evals │     t    ║ Grads │    Value   ║ \n",
      "═════╬════════════╬════════════════╬═════════════╬═══════════════════════╬════════════════════╣\n",
      " 200 ║  - │   -   ║ -0.00459922393 ║   -  │   -  ║ QN │     7 │ 0.015625 ║     1 │ 1.563062   ║ \n",
      " 210 ║  - │   -   ║ -0.00484215226 ║   -  │   -  ║ QN │     6 │ 0.031250 ║     1 │ 0.683824   ║ \n",
      " 220 ║  - │   -   ║ -0.00491936735 ║   -  │   -  ║ QN │     2 │ 0.500000 ║     1 │ 0.041648   ║ \n",
      " 230 ║  - │   -   ║ -0.00518176769 ║   -  │   -  ║ QN │     7 │ 0.015625 ║     1 │ 0.227567   ║ \n",
      " 240 ║  - │   -   ║ -0.00566808497 ║   -  │   -  ║ QN │     3 │ 0.250000 ║     1 │ 0.017318   ║ \n",
      " 250 ║  - │   -   ║ -0.00605138773 ║   -  │   -  ║ QN │     6 │ 0.031250 ║     1 │ 0.197022   ║ \n",
      " 260 ║  - │   -   ║ -0.00620501715 ║   -  │   -  ║ QN │     7 │ 0.046875 ║     1 │ 0.050527   ║ \n",
      " 270 ║  - │   -   ║ -0.00626350977 ║   -  │   -  ║ QN │     8 │ 0.007812 ║     1 │ 0.865589   ║ \n",
      " 280 ║  - │   -   ║ -0.00630147970 ║   -  │   -  ║ QN │     1 │ 1.000000 ║     1 │ 0.016533   ║ \n",
      " 290 ║  - │   -   ║ -0.00635672018 ║   -  │   -  ║ QN │    10 │ 0.001953 ║     1 │ 0.363580   ║ \n",
      " 300 ║  - │   -   ║ -0.00638951394 ║   -  │   -  ║ QN │    14 │ 0.001831 ║     1 │ 1.863748   ║ \n",
      " 310 ║  - │   -   ║ -0.00645520761 ║   -  │   -  ║ QN │    13 │ 2.44e-04 ║     1 │ 1.236437   ║ \n",
      " 320 ║  - │   -   ║ -0.00656191571 ║   -  │   -  ║ QN │    10 │ 0.017578 ║     1 │ 0.663035   ║ \n",
      " 330 ║  - │   -   ║ -0.00664104363 ║   -  │   -  ║ QN │     7 │ 0.046875 ║     1 │ 1.584105   ║ \n",
      " 340 ║  - │   -   ║ -0.00678524034 ║   -  │   -  ║ QN │     2 │ 0.500000 ║     1 │ 0.005646   ║ \n",
      " 350 ║  - │   -   ║ -0.00684336642 ║   -  │   -  ║ QN │     7 │ 0.015625 ║     1 │ 0.141430   ║ \n",
      " 360 ║  - │   -   ║ -0.00692720188 ║   -  │   -  ║ QN │     7 │ 0.078125 ║     1 │ 0.350007   ║ \n",
      " 370 ║  - │   -   ║ -0.00696454813 ║   -  │   -  ║ QN │     1 │ 1.000000 ║     1 │ 0.005738   ║ \n",
      " 380 ║  - │   -   ║ -0.00698405432 ║   -  │   -  ║ QN │    10 │ 0.001953 ║     1 │ 0.900453   ║ \n",
      " 390 ║  - │   -   ║ -0.00698899733 ║   -  │   -  ║ QN │     5 │ 0.062500 ║     1 │ 0.019866   ║ \n",
      "═════╬════════════╬════════════════╬═════════════╬═══════════════════════╬════════════════════╣\n",
      "     ║ Penalty Fn ║                ║  Violation  ║ <--- Line Search ---> ║ <- Stationarity -> ║ \n",
      "Iter ║ Mu │ Value ║    Objective   ║ Ineq │  Eq  ║ SD │ Evals │     t    ║ Grads │    Value   ║ \n",
      "═════╬════════════╬════════════════╬═════════════╬═══════════════════════╬════════════════════╣\n",
      " 400 ║  - │   -   ║ -0.00699936540 ║   -  │   -  ║ QN │     2 │ 0.500000 ║     1 │ 0.008296   ║ \n",
      " 410 ║  - │   -   ║ -0.00701327880 ║   -  │   -  ║ QN │    12 │ 0.002441 ║     1 │ 1.455627   ║ \n",
      " 420 ║  - │   -   ║ -0.00705543344 ║   -  │   -  ║ QN │    16 │ 3.05e-05 ║     1 │ 5.903243   ║ \n",
      " 430 ║  - │   -   ║ -0.00713476374 ║   -  │   -  ║ QN │     8 │ 0.007812 ║     1 │ 0.633470   ║ \n",
      " 440 ║  - │   -   ║ -0.00718647979 ║   -  │   -  ║ QN │    13 │ 7.32e-04 ║     1 │ 0.950399   ║ \n",
      " 450 ║  - │   -   ║ -0.00723629124 ║   -  │   -  ║ QN │     5 │ 0.062500 ║     1 │ 0.001822   ║ \n",
      " 460 ║  - │   -   ║ -0.00725354439 ║   -  │   -  ║ QN │     6 │ 0.156250 ║     1 │ 0.307587   ║ \n",
      " 470 ║  - │   -   ║ -0.00728068470 ║   -  │   -  ║ QN │     6 │ 0.031250 ║     1 │ 0.003089   ║ \n",
      " 480 ║  - │   -   ║ -0.00740677357 ║   -  │   -  ║ QN │     7 │ 0.046875 ║     1 │ 0.404591   ║ \n",
      " 490 ║  - │   -   ║ -0.00745484729 ║   -  │   -  ║ QN │    13 │ 0.001709 ║     1 │ 1.287981   ║ \n",
      " 500 ║  - │   -   ║ -0.00749253307 ║   -  │   -  ║ QN │     3 │ 0.250000 ║     1 │ 0.006342   ║ \n",
      " 510 ║  - │   -   ║ -0.00753750710 ║   -  │   -  ║ QN │     4 │ 0.125000 ║     1 │ 0.016868   ║ \n",
      " 520 ║  - │   -   ║ -0.00754973078 ║   -  │   -  ║ QN │    11 │ 0.008789 ║     1 │ 1.154647   ║ \n",
      " 530 ║  - │   -   ║ -0.00758182896 ║   -  │   -  ║ QN │    10 │ 0.025391 ║     1 │ 1.820551   ║ \n",
      " 540 ║  - │   -   ║ -0.00759204066 ║   -  │   -  ║ QN │     6 │ 0.031250 ║     1 │ 0.534377   ║ \n",
      " 550 ║  - │   -   ║ -0.00761201360 ║   -  │   -  ║ QN │     3 │ 0.250000 ║     1 │ 0.005719   ║ \n",
      " 560 ║  - │   -   ║ -0.00767929745 ║   -  │   -  ║ QN │    10 │ 0.017578 ║     1 │ 1.555477   ║ \n",
      " 570 ║  - │   -   ║ -0.00781994851 ║   -  │   -  ║ QN │     2 │ 0.500000 ║     1 │ 0.005769   ║ \n",
      " 580 ║  - │   -   ║ -0.00787706416 ║   -  │   -  ║ QN │     2 │ 0.500000 ║     1 │ 0.007248   ║ \n",
      " 590 ║  - │   -   ║ -0.00802282122 ║   -  │   -  ║ QN │     8 │ 0.007812 ║     1 │ 0.178152   ║ \n",
      "═════╬════════════╬════════════════╬═════════════╬═══════════════════════╬════════════════════╣\n",
      "     ║ Penalty Fn ║                ║  Violation  ║ <--- Line Search ---> ║ <- Stationarity -> ║ \n",
      "Iter ║ Mu │ Value ║    Objective   ║ Ineq │  Eq  ║ SD │ Evals │     t    ║ Grads │    Value   ║ \n",
      "═════╬════════════╬════════════════╬═════════════╬═══════════════════════╬════════════════════╣\n",
      " 600 ║  - │   -   ║ -0.00823802652 ║   -  │   -  ║ QN │     3 │ 0.250000 ║     1 │ 0.020793   ║ \n",
      " 610 ║  - │   -   ║ -0.00827957270 ║   -  │   -  ║ QN │     3 │ 0.250000 ║     1 │ 0.012844   ║ \n",
      " 620 ║  - │   -   ║ -0.00840509422 ║   -  │   -  ║ QN │     9 │ 0.011719 ║     1 │ 0.456101   ║ \n",
      " 630 ║  - │   -   ║ -0.00844587723 ║   -  │   -  ║ QN │    12 │ 0.001465 ║     1 │ 0.719685   ║ \n",
      " 640 ║  - │   -   ║ -0.00853567838 ║   -  │   -  ║ QN │    10 │ 0.005859 ║     1 │ 0.636514   ║ \n",
      " 650 ║  - │   -   ║ -0.00854686979 ║   -  │   -  ║ QN │    11 │ 9.77e-04 ║     1 │ 0.435651   ║ \n",
      " 660 ║  - │   -   ║ -0.00855925269 ║   -  │   -  ║ QN │     2 │ 0.500000 ║     1 │ 0.002290   ║ \n",
      " 670 ║  - │   -   ║ -0.00856319279 ║   -  │   -  ║ QN │    15 │ 4.27e-04 ║     1 │ 4.790205   ║ \n",
      " 680 ║  - │   -   ║ -0.00857367221 ║   -  │   -  ║ QN │     3 │ 0.250000 ║     1 │ 0.002534   ║ \n",
      " 690 ║  - │   -   ║ -0.00860253730 ║   -  │   -  ║ QN │     9 │ 0.027344 ║     1 │ 3.047306   ║ \n",
      " 700 ║  - │   -   ║ -0.00863965832 ║   -  │   -  ║ QN │     4 │ 0.125000 ║     1 │ 1.950785   ║ \n",
      " 710 ║  - │   -   ║ -0.00872621776 ║   -  │   -  ║ QN │    12 │ 0.001465 ║     1 │ 3.020013   ║ \n",
      " 720 ║  - │   -   ║ -0.00874193911 ║   -  │   -  ║ QN │     8 │ 0.007812 ║     1 │ 0.164666   ║ \n",
      " 730 ║  - │   -   ║ -0.00878411725 ║   -  │   -  ║ QN │    11 │ 9.77e-04 ║     1 │ 3.100327   ║ \n",
      " 740 ║  - │   -   ║ -0.00881608539 ║   -  │   -  ║ QN │    13 │ 0.001221 ║     1 │ 2.998468   ║ \n",
      " 750 ║  - │   -   ║ -0.00882482897 ║   -  │   -  ║ QN │     9 │ 0.011719 ║     1 │ 0.036757   ║ \n",
      " 760 ║  - │   -   ║ -0.00882628870 ║   -  │   -  ║ QN │    16 │ 9.16e-05 ║     1 │ 1.523831   ║ \n",
      " 770 ║  - │   -   ║ -0.00882888586 ║   -  │   -  ║ QN │     3 │ 0.250000 ║     1 │ 0.009361   ║ \n",
      " 780 ║  - │   -   ║ -0.00883300626 ║   -  │   -  ║ QN │    15 │ 0.001038 ║     1 │ 1.433849   ║ \n",
      " 790 ║  - │   -   ║ -0.00883375580 ║   -  │   -  ║ QN │     8 │ 0.007812 ║     1 │ 0.010550   ║ \n",
      "═════╬════════════╬════════════════╬═════════════╬═══════════════════════╬════════════════════╣\n",
      "     ║ Penalty Fn ║                ║  Violation  ║ <--- Line Search ---> ║ <- Stationarity -> ║ \n",
      "Iter ║ Mu │ Value ║    Objective   ║ Ineq │  Eq  ║ SD │ Evals │     t    ║ Grads │    Value   ║ \n",
      "═════╬════════════╬════════════════╬═════════════╬═══════════════════════╬════════════════════╣\n",
      " 800 ║  - │   -   ║ -0.00884015027 ║   -  │   -  ║ QN │    10 │ 0.001953 ║     2 │ 0.004193   ║ \n",
      " 810 ║  - │   -   ║ -0.00885070403 ║   -  │   -  ║ QN │     8 │ 0.007812 ║     1 │ 0.084376   ║ \n",
      " 820 ║  - │   -   ║ -0.00885131186 ║   -  │   -  ║ QN │     7 │ 0.015625 ║     2 │ 0.001767   ║ \n",
      " 830 ║  - │   -   ║ -0.00886233809 ║   -  │   -  ║ QN │     8 │ 0.007812 ║     1 │ 0.220185   ║ \n",
      " 840 ║  - │   -   ║ -0.00886528558 ║   -  │   -  ║ QN │    15 │ 6.10e-05 ║     1 │ 1.530184   ║ \n",
      " 850 ║  - │   -   ║ -0.00886658760 ║   -  │   -  ║ QN │     8 │ 0.007812 ║     4 │ 0.001077   ║ \n",
      " 860 ║  - │   -   ║ -0.00886754783 ║   -  │   -  ║ QN │    16 │ 9.16e-05 ║     1 │ 2.209083   ║ \n",
      " 870 ║  - │   -   ║ -0.00887955050 ║   -  │   -  ║ QN │    12 │ 0.003418 ║     1 │ 2.858612   ║ \n",
      " 880 ║  - │   -   ║ -0.00888638522 ║   -  │   -  ║ QN │     6 │ 0.031250 ║     1 │ 0.024457   ║ \n",
      " 890 ║  - │   -   ║ -0.00889893506 ║   -  │   -  ║ QN │     6 │ 0.093750 ║     1 │ 0.079081   ║ \n",
      " 900 ║  - │   -   ║ -0.00891507150 ║   -  │   -  ║ QN │    12 │ 0.001465 ║     1 │ 1.649853   ║ \n",
      " 910 ║  - │   -   ║ -0.00891914641 ║   -  │   -  ║ QN │     9 │ 0.003906 ║     1 │ 4.091866   ║ \n",
      " 920 ║  - │   -   ║ -0.00893387989 ║   -  │   -  ║ QN │    13 │ 2.44e-04 ║     1 │ 1.120328   ║ \n",
      " 930 ║  - │   -   ║ -0.00894544267 ║   -  │   -  ║ QN │     4 │ 0.125000 ║     1 │ 0.004424   ║ \n",
      " 940 ║  - │   -   ║ -0.00895337463 ║   -  │   -  ║ QN │    14 │ 3.66e-04 ║     1 │ 2.172300   ║ \n",
      " 950 ║  - │   -   ║ -0.00895861642 ║   -  │   -  ║ QN │     8 │ 0.007812 ║     1 │ 0.014405   ║ \n",
      " 960 ║  - │   -   ║ -0.00896653089 ║   -  │   -  ║ QN │     7 │ 0.015625 ║     1 │ 0.009997   ║ \n",
      " 970 ║  - │   -   ║ -0.00896982918 ║   -  │   -  ║ QN │     4 │ 0.125000 ║     1 │ 0.007420   ║ \n",
      " 980 ║  - │   -   ║ -0.00897254581 ║   -  │   -  ║ QN │    11 │ 9.77e-04 ║     1 │ 1.033967   ║ \n",
      " 990 ║  - │   -   ║ -0.00897390145 ║   -  │   -  ║ QN │    10 │ 0.001953 ║     1 │ 1.664432   ║ \n",
      "═════╬════════════╬════════════════╬═════════════╬═══════════════════════╬════════════════════╣\n",
      "     ║ Penalty Fn ║                ║  Violation  ║ <--- Line Search ---> ║ <- Stationarity -> ║ \n",
      "Iter ║ Mu │ Value ║    Objective   ║ Ineq │  Eq  ║ SD │ Evals │     t    ║ Grads │    Value   ║ \n",
      "═════╬════════════╬════════════════╬═════════════╬═══════════════════════╬════════════════════╣\n",
      "1000 ║  - │   -   ║ -0.00897429653 ║   -  │   -  ║ QN │    10 │ 0.005859 ║     2 │ 0.002725   ║ \n",
      "1010 ║  - │   -   ║ -0.00897436253 ║   -  │   -  ║ QN │    19 │ 1.11e-04 ║     4 │ 0.004689   ║ \n",
      "1020 ║  - │   -   ║ -0.00897441067 ║   -  │   -  ║ QN │    19 │ 3.81e-06 ║    10 │ 0.004097   ║ \n",
      "1030 ║  - │   -   ║ -0.00897441910 ║   -  │   -  ║ QN │    24 │ 8.34e-07 ║    19 │ 0.004261   ║ \n",
      "1040 ║  - │   -   ║ -0.00897442005 ║   -  │   -  ║ QN │    26 │ 5.66e-07 ║    29 │ 0.004018   ║ \n",
      "1050 ║  - │   -   ║ -0.00897442035 ║   -  │   -  ║ QN │    27 │ 4.47e-08 ║    38 │ 0.003928   ║ \n",
      "1060 ║  - │   -   ║ -0.00897442037 ║   -  │   -  ║ QN │    30 │ 5.59e-09 ║    48 │ 0.003771   ║ \n",
      "1070 ║  - │   -   ║ -0.00897442038 ║   -  │   -  ║ QN │    25 │ 5.96e-08 ║    58 │ 0.002230   ║ \n",
      "═════╩════════════╩════════════════╩═════════════╩═══════════════════════╩════════════════════╣\n",
      "Optimization results:                                                                         ║ \n",
      "F = final iterate, B = Best (to tolerance), MF = Most Feasible                                ║ \n",
      "═════╦════════════╦════════════════╦═════════════╦═══════════════════════╦════════════════════╣\n",
      "   F ║    │       ║ -0.00897442038 ║   -  │   -  ║    │       │          ║       │            ║ \n",
      "   B ║    │       ║ -0.00897442038 ║   -  │   -  ║    │       │          ║       │            ║ \n",
      "═════╩════════════╩════════════════╩═════════════╩═══════════════════════╩════════════════════╣\n",
      "Iterations:              1077                                                                 ║ \n",
      "Function evaluations:    9491                                                                 ║ \n",
      "PyGRANSO termination code: 6 --- line search bracketed a minimizer but failed to satisfy      ║ \n",
      "Wolfe conditions.  This may be an indication that approximate stationarity has been attained. ║ \n",
      "══════════════════════════════════════════════════════════════════════════════════════════════╝\n"
     ]
    }
   ],
   "source": [
    "opts = pygransoStruct()\n",
    "\n",
    "# PyGranso options\n",
    "# Increase max number of iterations and let convege to stationarity\n",
    "# Do we see local minima in the PyGranso version\n",
    "# Dual Annealing, SCIP and Deeplifting, PyGranso (showing there are local minima)\n",
    "opts.x0 = torch.reshape(w0, (-1, 1))\n",
    "opts.torch_device = device\n",
    "opts.print_frequency = 10\n",
    "opts.limited_mem_size = 5\n",
    "opts.stat_l2_model = False\n",
    "opts.double_precision = True\n",
    "opts.opt_tol = 1e-5\n",
    "opts.maxit = 10000\n",
    "\n",
    "# Run the main algorithm\n",
    "soln = pygranso(var_spec=var_in, combined_fn=comb_fn, user_opts=opts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f6c3d5ad-0570-45e1-b98a-a7939f461017",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deeplifting.models import DeepliftingSkipMLP\n",
    "from sklearn.datasets import load_iris\n",
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "071246b4-3669-43a1-9e44-3ae4fcbac3ee",
   "metadata": {},
   "source": [
    "# Deeplifting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7afd326d-5a22-420d-b191-1d903d7220ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the learning function\n",
    "def deeplifting_svm(model, inputs_X, labels):\n",
    "    outputs = model(None)\n",
    "    weight_vec = outputs.mean(axis=0)\n",
    "\n",
    "    # Compute SVM objective\n",
    "    denominator = torch.linalg.norm(weight_vec, ord=2)\n",
    "    prod = torch.matmul(weight_vec.T, inputs_X)\n",
    "    numerator = labels * prod\n",
    "    obj = numerator / denominator\n",
    "\n",
    "    # Orig obj\n",
    "    f = torch.amax(-1 * obj)\n",
    "\n",
    "    ce = None\n",
    "    ci = None\n",
    "    return f, ci, ce\n",
    "\n",
    "\n",
    "# # Set up a model\n",
    "# # Deeplifting model with skip connections\n",
    "# model = DeepliftingSkipMLP(\n",
    "#     input_size=128,\n",
    "#     hidden_sizes=(128,) * 3,\n",
    "#     output_size=65,\n",
    "#     bounds=None,\n",
    "#     skip_every_n=1,\n",
    "#     activation='leaky_relu',\n",
    "#     output_activation='sine',\n",
    "#     agg_function='identity',\n",
    "#     include_bn=True,\n",
    "#     seed=0,\n",
    "# )\n",
    "\n",
    "model = DeepliftingSkipMLP(\n",
    "    input_size=32,\n",
    "    hidden_sizes=(128,) * 4,\n",
    "    output_size=65,\n",
    "    bounds=None,\n",
    "    skip_every_n=1,\n",
    "    activation='leaky_relu',\n",
    "    output_activation='sine',\n",
    "    agg_function='identity',\n",
    "    include_bn=True,\n",
    "    seed=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df1cdc83-2166-423d-a84f-3479f3848616",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[33m╔═════ QP SOLVER NOTICE ════════════════════════════════════════════════════════════════════════╗\n",
      "\u001b[0m\u001b[33m║  PyGRANSO requires a quadratic program (QP) solver that has a quadprog-compatible interface,  ║\n",
      "\u001b[0m\u001b[33m║  the default is osqp. Users may provide their own wrapper for the QP solver.                  ║\n",
      "\u001b[0m\u001b[33m║  To disable this notice, set opts.quadprog_info_msg = False                                   ║\n",
      "\u001b[0m\u001b[33m╚═══════════════════════════════════════════════════════════════════════════════════════════════╝\n",
      "\u001b[0m═══════════════════════════════════════════════════════════════════════════════════════════════╗\n",
      "PyGRANSO: A PyTorch-enabled port of GRANSO with auto-differentiation                           ║ \n",
      "Version 1.2.0                                                                                  ║ \n",
      "Licensed under the AGPLv3, Copyright (C) 2021-2022 Tim Mitchell and Buyun Liang                ║ \n",
      "═══════════════════════════════════════════════════════════════════════════════════════════════╣\n",
      "Problem specifications:                                                                        ║ \n",
      " # of variables                     :   150983                                                 ║ \n",
      " # of inequality constraints        :        0                                                 ║ \n",
      " # of equality constraints          :        0                                                 ║ \n",
      "═══════════════════════════════════════════════════════════════════════════════════════════════╣\n",
      "\u001b[33mLimited-memory mode enabled with size = 100.                                                  \u001b[0m ║ \n",
      "\u001b[33mNOTE: limited-memory mode is generally NOT                                                    \u001b[0m ║ \n",
      "\u001b[33mrecommended for nonsmooth problems.                                                           \u001b[0m ║ \n",
      "══════╦════════════╦════════════════╦═════════════╦═══════════════════════╦════════════════════╣\n",
      "      ║ Penalty Fn ║                ║  Violation  ║ <--- Line Search ---> ║ <- Stationarity -> ║ \n",
      " Iter ║ Mu │ Value ║    Objective   ║ Ineq │  Eq  ║ SD │ Evals │     t    ║ Grads │    Value   ║ \n",
      "══════╬════════════╬════════════════╬═════════════╬═══════════════════════╬════════════════════╣\n",
      "    0 ║  - │   -   ║  0.30421316423 ║   -  │   -  ║ -  │     1 │ 0.000000 ║     1 │ 0.734425   ║ \n",
      "   10 ║  - │   -   ║  0.02377275011 ║   -  │   -  ║ QN │     4 │ 0.125000 ║     1 │ 0.015468   ║ \n",
      "   20 ║  - │   -   ║  0.01303111552 ║   -  │   -  ║ QN │     1 │ 1.000000 ║     1 │ 0.016527   ║ \n",
      "   30 ║  - │   -   ║  0.00760952303 ║   -  │   -  ║ QN │     3 │ 0.250000 ║     1 │ 0.015486   ║ \n",
      "   40 ║  - │   -   ║  0.00412657055 ║   -  │   -  ║ QN │     2 │ 0.500000 ║     1 │ 0.009029   ║ \n",
      "   50 ║  - │   -   ║  0.00186053810 ║   -  │   -  ║ QN │     1 │ 1.000000 ║     1 │ 0.017801   ║ \n",
      "   60 ║  - │   -   ║  2.2450723e-04 ║   -  │   -  ║ QN │     4 │ 0.125000 ║     1 │ 0.036928   ║ \n",
      "   70 ║  - │   -   ║ -0.00192549918 ║   -  │   -  ║ QN │     1 │ 1.000000 ║     1 │ 0.014564   ║ \n",
      "   80 ║  - │   -   ║ -0.00324169998 ║   -  │   -  ║ QN │     2 │ 0.500000 ║     1 │ 0.002956   ║ \n",
      "   90 ║  - │   -   ║ -0.00380884807 ║   -  │   -  ║ QN │     1 │ 1.000000 ║     1 │ 0.029900   ║ \n",
      "  100 ║  - │   -   ║ -0.00452608914 ║   -  │   -  ║ QN │     2 │ 2.000000 ║     1 │ 0.018217   ║ \n",
      "  110 ║  - │   -   ║ -0.00506573067 ║   -  │   -  ║ QN │     8 │ 0.023438 ║     1 │ 0.422430   ║ \n",
      "  120 ║  - │   -   ║ -0.00536763024 ║   -  │   -  ║ QN │     6 │ 0.031250 ║     1 │ 0.258360   ║ \n",
      "  130 ║  - │   -   ║ -0.00556334314 ║   -  │   -  ║ QN │     5 │ 0.062500 ║     1 │ 0.054827   ║ \n",
      "  140 ║  - │   -   ║ -0.00597443641 ║   -  │   -  ║ QN │     8 │ 0.007812 ║     1 │ 0.170692   ║ \n",
      "  150 ║  - │   -   ║ -0.00609005603 ║   -  │   -  ║ QN │     7 │ 0.015625 ║     1 │ 0.059481   ║ \n",
      "  160 ║  - │   -   ║ -0.00624631410 ║   -  │   -  ║ QN │     1 │ 1.000000 ║     1 │ 4.970711   ║ \n",
      "  170 ║  - │   -   ║ -0.00649009250 ║   -  │   -  ║ QN │     5 │ 0.062500 ║     1 │ 2.192162   ║ \n",
      "  180 ║  - │   -   ║ -0.00666871433 ║   -  │   -  ║ QN │    12 │ 0.001465 ║     1 │ 0.794136   ║ \n",
      "  190 ║  - │   -   ║ -0.00672218844 ║   -  │   -  ║ QN │    16 │ 3.05e-05 ║     1 │ 12.18221   ║ \n",
      "══════╬════════════╬════════════════╬═════════════╬═══════════════════════╬════════════════════╣\n",
      "      ║ Penalty Fn ║                ║  Violation  ║ <--- Line Search ---> ║ <- Stationarity -> ║ \n",
      " Iter ║ Mu │ Value ║    Objective   ║ Ineq │  Eq  ║ SD │ Evals │     t    ║ Grads │    Value   ║ \n",
      "══════╬════════════╬════════════════╬═════════════╬═══════════════════════╬════════════════════╣\n",
      "  200 ║  - │   -   ║ -0.00698267178 ║   -  │   -  ║ QN │     6 │ 0.031250 ║     1 │ 3.891808   ║ \n",
      "  210 ║  - │   -   ║ -0.00715431962 ║   -  │   -  ║ QN │    11 │ 9.77e-04 ║     1 │ 8.989916   ║ \n"
     ]
    }
   ],
   "source": [
    "# Deeplifting time!\n",
    "device = torch.device('cpu')\n",
    "model = model.to(device=device, dtype=torch.double)\n",
    "nvar = getNvarTorch(model.parameters())\n",
    "\n",
    "opts = pygransoStruct()\n",
    "\n",
    "# Inital x0\n",
    "x0 = (\n",
    "    torch.nn.utils.parameters_to_vector(model.parameters())\n",
    "    .detach()\n",
    "    .reshape(nvar, 1)\n",
    "    .to(device=device, dtype=torch.double)\n",
    ")\n",
    "\n",
    "# PyGranso options\n",
    "# Increase max number of iterations and let convege to stationarity\n",
    "# Do we see local minima in the PyGranso version\n",
    "# Dual Annealing, SCIP and Deeplifting, PyGranso (showing there are local minima)\n",
    "opts.x0 = x0\n",
    "opts.torch_device = device\n",
    "opts.print_frequency = 10\n",
    "opts.limited_mem_size = 100\n",
    "opts.stat_l2_model = False\n",
    "opts.double_precision = True\n",
    "opts.opt_tol = 1e-5\n",
    "opts.maxit = 10000\n",
    "\n",
    "# Combined function\n",
    "comb_fn = lambda model: deeplifting_svm(model, inputs_X, labels)  # noqa\n",
    "\n",
    "# Run the main algorithm\n",
    "soln = pygranso(var_spec=model, combined_fn=comb_fn, user_opts=opts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc5e3cda-27f3-4be7-9263-f747bb84f214",
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba0bcdd8-61e3-4237-95c9-367da94aa0ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeplifting",
   "language": "python",
   "name": "deeplifting"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
