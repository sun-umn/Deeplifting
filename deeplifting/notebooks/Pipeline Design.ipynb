{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d1aaf72f-9539-422e-ac7a-06783f883f94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/ryandevera/data-science/umn_environments/Deeplifting\n"
     ]
    }
   ],
   "source": [
    "%pwd\n",
    "%cd ../.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d666d7fd-d138-49c7-b89d-a073fbc75fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from deeplifting.problems import PROBLEMS_BY_NAME\n",
    "from deeplifting.optimization import (\n",
    "    run_deeplifting,\n",
    "    run_differential_evolution,\n",
    "    run_dual_annealing,\n",
    "    run_ipopt,\n",
    "    run_pygranso,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bc151516-0f7e-425b-9109-97b1deede3c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "problem_name = 'shubert'\n",
    "problem = PROBLEMS_BY_NAME[problem_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b766647d-1e8b-4069-a828-0bdc4e8fce91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_gpus: 0\n",
      "tensor([0.9701, 0.7078], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "\n",
      "\n",
      "\u001b[33m╔═════ QP SOLVER NOTICE ════════════════════════════════════════════════════════════════════════╗\n",
      "\u001b[0m\u001b[33m║  PyGRANSO requires a quadratic program (QP) solver that has a quadprog-compatible interface,  ║\n",
      "\u001b[0m\u001b[33m║  the default is osqp. Users may provide their own wrapper for the QP solver.                  ║\n",
      "\u001b[0m\u001b[33m║  To disable this notice, set opts.quadprog_info_msg = False                                   ║\n",
      "\u001b[0m\u001b[33m╚═══════════════════════════════════════════════════════════════════════════════════════════════╝\n",
      "\u001b[0m═════════════════════════════════════════════════════════════════════════════════════════════════════════════════╗\n",
      "PyGRANSO: A PyTorch-enabled port of GRANSO with auto-differentiation                                             ║ \n",
      "Version 1.2.0                                                                                                    ║ \n",
      "Licensed under the AGPLv3, Copyright (C) 2021-2022 Tim Mitchell and Buyun Liang                                  ║ \n",
      "═════════════════════════════════════════════════════════════════════════════════════════════════════════════════╣\n",
      "Problem specifications:                                                                                          ║ \n",
      " # of variables                     :   2                                                                        ║ \n",
      " # of inequality constraints        :   4                                                                        ║ \n",
      " # of equality constraints          :   0                                                                        ║ \n",
      "═════════════════════════════════════════════════════════════════════════════════════════════════════════════════╣\n",
      "\u001b[33mLimited-memory mode enabled with size = 150.                                                                    \u001b[0m ║ \n",
      "\u001b[33mNOTE: limited-memory mode is generally NOT                                                                      \u001b[0m ║ \n",
      "\u001b[33mrecommended for nonsmooth problems.                                                                             \u001b[0m ║ \n",
      "═════╦═══════════════════════════╦════════════════╦═════════════════╦═══════════════════════╦════════════════════╣\n",
      "     ║ <--- Penalty Function --> ║                ║ Total Violation ║ <--- Line Search ---> ║ <- Stationarity -> ║ \n",
      "Iter ║    Mu    │      Value     ║    Objective   ║   Ineq   │  Eq  ║ SD │ Evals │     t    ║ Grads │    Value   ║ \n",
      "═════╬═══════════════════════════╬════════════════╬═════════════════╬═══════════════════════╬════════════════════╣\n",
      "   0 ║ 1.000000 │  6.63783206339 ║  6.63783206339 ║ 0.000000 │   -  ║ -  │     1 │ 0.000000 ║     1 │ 48.47957   ║ \n",
      "tensor([ 49.4496, -34.3103], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([ 25.2098, -16.8012], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([13.0899, -8.0467], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([10.8762, -2.7240], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([11.9831, -5.3854], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([-17.3189,  33.5133], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([-2.6679, 14.0640], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([4.6576, 4.3393], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([10.6323, -3.8468], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([7.6449, 0.2463], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([6.1512, 2.2928], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([5.4044, 3.3160], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([5.0310, 3.8277], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([4.8443, 4.0835], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([4.7509, 4.2114], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([4.9858, 4.3080], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([4.8683, 4.2597], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([4.8543, 4.2851], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([4.8578, 4.2758], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([4.8581, 4.2760], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([4.8581, 4.2760], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([4.8581, 4.2760], dtype=torch.float64, grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ryandevera/.virtualenvs/deeplifing/lib/python3.9/site-packages/pygranso/private/bfgsHessianInverseLimitedMem.py:237: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matrices or `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3575.)\n",
      "  alpha[j,:]  = self.rho[0,j] * (self.S[:,j].T  @ q)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([4.8581, 4.2760], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([4.8581, 4.2760], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([4.8581, 4.2760], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([4.8581, 4.2760], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([4.8581, 4.2760], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([4.8581, 4.2760], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([4.8581, 4.2760], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([4.8581, 4.2760], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "═════╩═══════════════════════════╩════════════════╩═════════════════╩═══════════════════════╩════════════════════╣\n",
      "Optimization results:                                                                                            ║ \n",
      "F = final iterate, B = Best (to tolerance), MF = Most Feasible                                                   ║ \n",
      "═════╦═══════════════════════════╦════════════════╦═════════════════╦═══════════════════════╦════════════════════╣\n",
      "   F ║          │                ║ -79.4109132229 ║ 0.000000 │   -  ║    │       │          ║       │            ║ \n",
      "   B ║          │                ║ -79.4109132229 ║ 0.000000 │   -  ║    │       │          ║       │            ║ \n",
      "  MF ║          │                ║ -79.4109132229 ║ 0.000000 │   -  ║    │       │          ║       │            ║ \n",
      "═════╩═══════════════════════════╩════════════════╩═════════════════╩═══════════════════════╩════════════════════╣\n",
      "Iterations:              12                                                                                      ║ \n",
      "Function evaluations:    31                                                                                      ║ \n",
      "PyGRANSO termination code: 6 --- line search bracketed a minimizer but failed to satisfy Wolfe conditions at a   ║ \n",
      "(strictly) feasible point.  This may be an indication that approximate stationarity has been attained.           ║ \n",
      "═════════════════════════════════════════════════════════════════════════════════════════════════════════════════╝\n",
      "tensor([0.0611, 0.2246], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "\n",
      "\n",
      "\u001b[33m╔═════ QP SOLVER NOTICE ════════════════════════════════════════════════════════════════════════╗\n",
      "\u001b[0m\u001b[33m║  PyGRANSO requires a quadratic program (QP) solver that has a quadprog-compatible interface,  ║\n",
      "\u001b[0m\u001b[33m║  the default is osqp. Users may provide their own wrapper for the QP solver.                  ║\n",
      "\u001b[0m\u001b[33m║  To disable this notice, set opts.quadprog_info_msg = False                                   ║\n",
      "\u001b[0m\u001b[33m╚═══════════════════════════════════════════════════════════════════════════════════════════════╝\n",
      "\u001b[0m═════════════════════════════════════════════════════════════════════════════════════════════════════════════════╗\n",
      "PyGRANSO: A PyTorch-enabled port of GRANSO with auto-differentiation                                             ║ \n",
      "Version 1.2.0                                                                                                    ║ \n",
      "Licensed under the AGPLv3, Copyright (C) 2021-2022 Tim Mitchell and Buyun Liang                                  ║ \n",
      "═════════════════════════════════════════════════════════════════════════════════════════════════════════════════╣\n",
      "Problem specifications:                                                                                          ║ \n",
      " # of variables                     :   2                                                                        ║ \n",
      " # of inequality constraints        :   4                                                                        ║ \n",
      " # of equality constraints          :   0                                                                        ║ \n",
      "═════════════════════════════════════════════════════════════════════════════════════════════════════════════════╣\n",
      "\u001b[33mLimited-memory mode enabled with size = 150.                                                                    \u001b[0m ║ \n",
      "\u001b[33mNOTE: limited-memory mode is generally NOT                                                                      \u001b[0m ║ \n",
      "\u001b[33mrecommended for nonsmooth problems.                                                                             \u001b[0m ║ \n",
      "═════╦═══════════════════════════╦════════════════╦═════════════════╦═══════════════════════╦════════════════════╣\n",
      "     ║ <--- Penalty Function --> ║                ║ Total Violation ║ <--- Line Search ---> ║ <- Stationarity -> ║ \n",
      "Iter ║    Mu    │      Value     ║    Objective   ║   Ineq   │  Eq  ║ SD │ Evals │     t    ║ Grads │    Value   ║ \n",
      "═════╬═══════════════════════════╬════════════════╬═════════════════╬═══════════════════════╬════════════════════╣\n",
      "   0 ║ 1.000000 │ -6.14511953447 ║ -6.14511953447 ║ 0.000000 │   -  ║ -  │     1 │ 0.000000 ║     1 │ 99.55815   ║ \n",
      "tensor([-99.4971,  43.9880], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([-49.7180,  22.1063], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([-24.8285,  11.1654], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([-14.4844,   6.8793], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([-19.6565,   9.0224], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([-22.2425,  10.0939], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([-23.5355,  10.6296], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([-24.1820,  10.8975], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([-24.5052,  11.0315], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([-24.6669,  11.0984], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([-24.7477,  11.1319], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([-24.7881,  11.1487], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([-25.2291,   9.1308], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([-25.0086,  10.1397], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([-24.8983,  10.6442], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([-24.8432,  10.8964], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([-24.8156,  11.0225], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([-24.8019,  11.0856], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([-24.7950,  11.1171], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([-24.7915,  11.1329], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([-24.7935,  11.1350], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([-24.7955,  11.1371], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([-24.7954,  11.1368], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([-24.7953,  11.1365], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([-24.7951,  11.1355], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([-24.7950,  11.1347], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([-24.7947,  11.1338], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([-24.7945,  11.1329], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([-24.7941,  11.1319], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([-24.7935,  11.1309], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([-24.7929,  11.1297], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([-24.7922,  11.1285], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([-24.7914,  11.1271], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([-24.7904,  11.1257], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([-24.7894,  11.1241], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([-24.7883,  11.1222], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([-24.7870,  11.1202], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([-24.7856,  11.1179], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([-24.7841,  11.1153], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([-24.7824,  11.1123], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([-24.7806,  11.1090], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([-24.7785,  11.1052], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([-24.7762,  11.1009], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([-24.7736,  11.0960], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([-24.7707,  11.0905], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([-24.7673,  11.0842], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([-24.7635,  11.0769], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([-24.7591,  11.0684], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([-24.7538,  11.0584], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([-24.7475,  11.0463], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([-24.7396,  11.0312], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([-24.7291,  11.0113], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([-24.7133,  10.9811], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([-24.6784,  10.9151], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([-24.6435,  10.8490], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([-24.5737,  10.7169], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([-24.4342,  10.4526], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([-24.1551,   9.9241], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([-23.5969,   8.8670], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([-22.4805,   6.7529], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([-20.2478,   2.5246], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([-15.7822,  -5.9320], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([ -6.8512, -22.8452], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([-10.0000, -16.8789], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([-13.1488, -10.9126], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([-19.4464,   1.0200], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([-13.6295, -10.0000], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([-13.6281, -10.0000], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([-13.6268, -10.0000], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([-13.6241, -10.0000], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([-13.6187, -10.0000], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([-13.6079, -10.0000], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([-13.5863, -10.0000], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([-13.5432, -10.0000], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([-13.4569, -10.0000], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([-13.2843, -10.0000], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([-12.9392, -10.0000], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([-12.2490, -10.0000], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([-10.8685, -10.0000], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([ -8.1074, -10.0000], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([-8.6475, -8.6360], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([-8.3775, -9.3180], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([-8.2424, -9.6590], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([-8.7657, -9.7288], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([-8.5041, -9.6939], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([-8.3733, -9.6765], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([-8.2697, -9.8257], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([-8.2966, -9.7755], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([-8.2892, -9.7801], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([-8.2906, -9.7806], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([-8.2904, -9.7804], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([-8.2904, -9.7804], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([-8.2904, -9.7804], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([-8.2904, -9.7804], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([-8.2904, -9.7804], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([-8.2904, -9.7804], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([-8.2904, -9.7804], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "═════╩═══════════════════════════╩════════════════╩═════════════════╩═══════════════════════╩════════════════════╣\n",
      "Optimization results:                                                                                            ║ \n",
      "F = final iterate, B = Best (to tolerance), MF = Most Feasible                                                   ║ \n",
      "═════╦═══════════════════════════╦════════════════╦═════════════════╦═══════════════════════╦════════════════════╣\n",
      "   F ║          │                ║ -16.2860995982 ║ 0.000000 │   -  ║    │       │          ║       │            ║ \n",
      "   B ║          │                ║ -16.2860995982 ║ 0.000000 │   -  ║    │       │          ║       │            ║ \n",
      "  MF ║          │                ║ -16.2860995982 ║ 0.000000 │   -  ║    │       │          ║       │            ║ \n",
      "═════╩═══════════════════════════╩════════════════╩═════════════════╩═══════════════════════╩════════════════════╣\n",
      "Iterations:              48                                                                                      ║ \n",
      "Function evaluations:    98                                                                                      ║ \n",
      "PyGRANSO termination code: 6 --- line search bracketed a minimizer but failed to satisfy Wolfe conditions at a   ║ \n",
      "(strictly) feasible point.  This may be an indication that approximate stationarity has been attained.           ║ \n",
      "═════════════════════════════════════════════════════════════════════════════════════════════════════════════════╝\n",
      "tensor([0.9176, 0.0969], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "\n",
      "\n",
      "\u001b[33m╔═════ QP SOLVER NOTICE ════════════════════════════════════════════════════════════════════════╗\n",
      "\u001b[0m\u001b[33m║  PyGRANSO requires a quadratic program (QP) solver that has a quadprog-compatible interface,  ║\n",
      "\u001b[0m\u001b[33m║  the default is osqp. Users may provide their own wrapper for the QP solver.                  ║\n",
      "\u001b[0m\u001b[33m║  To disable this notice, set opts.quadprog_info_msg = False                                   ║\n",
      "\u001b[0m\u001b[33m╚═══════════════════════════════════════════════════════════════════════════════════════════════╝\n",
      "\u001b[0m═════════════════════════════════════════════════════════════════════════════════════════════════════════════════╗\n",
      "PyGRANSO: A PyTorch-enabled port of GRANSO with auto-differentiation                                             ║ \n",
      "Version 1.2.0                                                                                                    ║ \n",
      "Licensed under the AGPLv3, Copyright (C) 2021-2022 Tim Mitchell and Buyun Liang                                  ║ \n",
      "═════════════════════════════════════════════════════════════════════════════════════════════════════════════════╣\n",
      "Problem specifications:                                                                                          ║ \n",
      " # of variables                     :   2                                                                        ║ \n",
      " # of inequality constraints        :   4                                                                        ║ \n",
      " # of equality constraints          :   0                                                                        ║ \n",
      "═════════════════════════════════════════════════════════════════════════════════════════════════════════════════╣\n",
      "\u001b[33mLimited-memory mode enabled with size = 150.                                                                    \u001b[0m ║ \n",
      "\u001b[33mNOTE: limited-memory mode is generally NOT                                                                      \u001b[0m ║ \n",
      "\u001b[33mrecommended for nonsmooth problems.                                                                             \u001b[0m ║ \n",
      "═════╦═══════════════════════════╦════════════════╦═════════════════╦═══════════════════════╦════════════════════╣\n",
      "     ║ <--- Penalty Function --> ║                ║ Total Violation ║ <--- Line Search ---> ║ <- Stationarity -> ║ \n",
      "Iter ║    Mu    │      Value     ║    Objective   ║   Ineq   │  Eq  ║ SD │ Evals │     t    ║ Grads │    Value   ║ \n",
      "═════╬═══════════════════════════╬════════════════╬═════════════════╬═══════════════════════╬════════════════════╣\n",
      "   0 ║ 1.000000 │  2.95523520037 ║  2.95523520037 ║ 0.000000 │   -  ║ -  │     1 │ 0.000000 ║     1 │ 109.7233   ║ \n",
      "tensor([ 11.7064, 109.8202], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([ 6.3120, 54.9585], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([ 3.6148, 27.5277], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([ 2.2662, 13.8123], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([1.5919, 6.9546], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([-0.1491,  6.9668], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([0.7214, 6.9607], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([1.1566, 6.9577], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([1.1395, 7.4929], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([1.1481, 7.2253], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([1.8851, 7.2857], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([1.5166, 7.2555], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([1.3323, 7.2404], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([1.4533, 6.9678], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([1.3928, 7.1041], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([1.3076, 7.0954], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([1.3204, 7.1068], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([1.3201, 7.1048], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([1.3200, 7.1050], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([1.3200, 7.1050], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([1.3200, 7.1050], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([1.3200, 7.1050], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([1.3200, 7.1050], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "═════╩═══════════════════════════╩════════════════╩═════════════════╩═══════════════════════╩════════════════════╣\n",
      "Optimization results:                                                                                            ║ \n",
      "F = final iterate, B = Best (to tolerance), MF = Most Feasible                                                   ║ \n",
      "═════╦═══════════════════════════╦════════════════╦═════════════════╦═══════════════════════╦════════════════════╣\n",
      "   F ║          │                ║ -10.9785588815 ║ 0.000000 │   -  ║    │       │          ║       │            ║ \n",
      "   B ║          │                ║ -10.9785588815 ║ 0.000000 │   -  ║    │       │          ║       │            ║ \n",
      "  MF ║          │                ║ -10.9785588815 ║ 0.000000 │   -  ║    │       │          ║       │            ║ \n",
      "═════╩═══════════════════════════╩════════════════╩═════════════════╩═══════════════════════╩════════════════════╣\n",
      "Iterations:              13                                                                                      ║ \n",
      "Function evaluations:    24                                                                                      ║ \n",
      "PyGRANSO termination code: 0 --- converged to stationarity and feasibility tolerances.                           ║ \n",
      "═════════════════════════════════════════════════════════════════════════════════════════════════════════════════╝\n",
      "tensor([0.0341, 0.2867], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "\n",
      "\n",
      "\u001b[33m╔═════ QP SOLVER NOTICE ════════════════════════════════════════════════════════════════════════╗\n",
      "\u001b[0m\u001b[33m║  PyGRANSO requires a quadratic program (QP) solver that has a quadprog-compatible interface,  ║\n",
      "\u001b[0m\u001b[33m║  the default is osqp. Users may provide their own wrapper for the QP solver.                  ║\n",
      "\u001b[0m\u001b[33m║  To disable this notice, set opts.quadprog_info_msg = False                                   ║\n",
      "\u001b[0m\u001b[33m╚═══════════════════════════════════════════════════════════════════════════════════════════════╝\n",
      "\u001b[0m═════════════════════════════════════════════════════════════════════════════════════════════════════════════════╗\n",
      "PyGRANSO: A PyTorch-enabled port of GRANSO with auto-differentiation                                             ║ \n",
      "Version 1.2.0                                                                                                    ║ \n",
      "Licensed under the AGPLv3, Copyright (C) 2021-2022 Tim Mitchell and Buyun Liang                                  ║ \n",
      "═════════════════════════════════════════════════════════════════════════════════════════════════════════════════╣\n",
      "Problem specifications:                                                                                          ║ \n",
      " # of variables                     :   2                                                                        ║ \n",
      " # of inequality constraints        :   4                                                                        ║ \n",
      " # of equality constraints          :   0                                                                        ║ \n",
      "═════════════════════════════════════════════════════════════════════════════════════════════════════════════════╣\n",
      "\u001b[33mLimited-memory mode enabled with size = 150.                                                                    \u001b[0m ║ \n",
      "\u001b[33mNOTE: limited-memory mode is generally NOT                                                                      \u001b[0m ║ \n",
      "\u001b[33mrecommended for nonsmooth problems.                                                                             \u001b[0m ║ \n",
      "═════╦═══════════════════════════╦════════════════╦═════════════════╦═══════════════════════╦════════════════════╣\n",
      "     ║ <--- Penalty Function --> ║                ║ Total Violation ║ <--- Line Search ---> ║ <- Stationarity -> ║ \n",
      "Iter ║    Mu    │      Value     ║    Objective   ║   Ineq   │  Eq  ║ SD │ Evals │     t    ║ Grads │    Value   ║ \n",
      "═════╬═══════════════════════════╬════════════════╬═════════════════╬═══════════════════════╬════════════════════╣\n",
      "   0 ║ 1.000000 │ -11.7626413378 ║ -11.7626413378 ║ 0.000000 │   -  ║ -  │     1 │ 0.000000 ║     1 │ 132.1633   ║ \n",
      "tensor([-132.1292,   27.6662], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([-66.0476,  13.9765], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([-33.0067,   7.1316], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([-16.4863,   3.7092], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([-8.2261,  1.9980], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([-4.0960,  1.1423], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([-2.0309,  0.7145], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([-2.5384,  1.8490], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([-2.2847,  1.2818], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([-2.1578,  0.9982], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([-2.0944,  0.8564], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([-1.5976,  0.9991], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([-1.8460,  0.9277], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([-1.9702,  0.8921], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([-2.0062,  0.8178], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([-2.0076,  0.8222], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([-2.0072,  0.8218], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([-2.0072,  0.8218], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([-2.0072,  0.8218], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([-2.0072,  0.8218], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([-2.0072,  0.8218], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([-2.0072,  0.8218], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([-2.0072,  0.8218], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([-2.0072,  0.8218], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([-2.0072,  0.8218], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([-2.0072,  0.8218], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([-2.0072,  0.8218], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([-2.0072,  0.8218], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "═════╩═══════════════════════════╩════════════════╩═════════════════╩═══════════════════════╩════════════════════╣\n",
      "Optimization results:                                                                                            ║ \n",
      "F = final iterate, B = Best (to tolerance), MF = Most Feasible                                                   ║ \n",
      "═════╦═══════════════════════════╦════════════════╦═════════════════╦═══════════════════════╦════════════════════╣\n",
      "   F ║          │                ║ -23.1367162265 ║ 0.000000 │   -  ║    │       │          ║       │            ║ \n",
      "   B ║          │                ║ -23.1367162265 ║ 0.000000 │   -  ║    │       │          ║       │            ║ \n",
      "  MF ║          │                ║ -23.1367162265 ║ 0.000000 │   -  ║    │       │          ║       │            ║ \n",
      "═════╩═══════════════════════════╩════════════════╩═════════════════╩═══════════════════════╩════════════════════╣\n",
      "Iterations:              9                                                                                       ║ \n",
      "Function evaluations:    29                                                                                      ║ \n",
      "PyGRANSO termination code: 6 --- line search bracketed a minimizer but failed to satisfy Wolfe conditions at a   ║ \n",
      "(strictly) feasible point.  This may be an indication that approximate stationarity has been attained.           ║ \n",
      "═════════════════════════════════════════════════════════════════════════════════════════════════════════════════╝\n",
      "tensor([0.4771, 0.7317], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "\n",
      "\n",
      "\u001b[33m╔═════ QP SOLVER NOTICE ════════════════════════════════════════════════════════════════════════╗\n",
      "\u001b[0m\u001b[33m║  PyGRANSO requires a quadratic program (QP) solver that has a quadprog-compatible interface,  ║\n",
      "\u001b[0m\u001b[33m║  the default is osqp. Users may provide their own wrapper for the QP solver.                  ║\n",
      "\u001b[0m\u001b[33m║  To disable this notice, set opts.quadprog_info_msg = False                                   ║\n",
      "\u001b[0m\u001b[33m╚═══════════════════════════════════════════════════════════════════════════════════════════════╝\n",
      "\u001b[0m═════════════════════════════════════════════════════════════════════════════════════════════════════════════════╗\n",
      "PyGRANSO: A PyTorch-enabled port of GRANSO with auto-differentiation                                             ║ \n",
      "Version 1.2.0                                                                                                    ║ \n",
      "Licensed under the AGPLv3, Copyright (C) 2021-2022 Tim Mitchell and Buyun Liang                                  ║ \n",
      "═════════════════════════════════════════════════════════════════════════════════════════════════════════════════╣\n",
      "Problem specifications:                                                                                          ║ \n",
      " # of variables                     :   2                                                                        ║ \n",
      " # of inequality constraints        :   4                                                                        ║ \n",
      " # of equality constraints          :   0                                                                        ║ \n",
      "═════════════════════════════════════════════════════════════════════════════════════════════════════════════════╣\n",
      "\u001b[33mLimited-memory mode enabled with size = 150.                                                                    \u001b[0m ║ \n",
      "\u001b[33mNOTE: limited-memory mode is generally NOT                                                                      \u001b[0m ║ \n",
      "\u001b[33mrecommended for nonsmooth problems.                                                                             \u001b[0m ║ \n",
      "═════╦═══════════════════════════╦════════════════╦═════════════════╦═══════════════════════╦════════════════════╣\n",
      "     ║ <--- Penalty Function --> ║                ║ Total Violation ║ <--- Line Search ---> ║ <- Stationarity -> ║ \n",
      "Iter ║    Mu    │      Value     ║    Objective   ║   Ineq   │  Eq  ║ SD │ Evals │     t    ║ Grads │    Value   ║ \n",
      "═════╬═══════════════════════════╬════════════════╬═════════════════╬═══════════════════════╬════════════════════╣\n",
      "   0 ║ 1.000000 │ -7.07983732815 ║ -7.07983732815 ║ 0.000000 │   -  ║ -  │     1 │ 0.000000 ║     1 │ 63.82667   ║ \n",
      "tensor([-63.3496,  27.6321], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([-31.4362,  14.1819], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([-15.4796,   7.4568], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([-7.5012,  4.0942], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([-11.4904,   5.7755], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([-9.4958,  4.9348], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([-1.8003,  2.2831], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([-5.6481,  3.6090], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([-7.5719,  4.2719], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([-8.6113,  4.1958], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([-8.0916,  4.2338], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([-7.8318,  4.2529], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([-7.8375,  5.5567], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([-7.6105,  4.6793], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([-7.7240,  5.1180], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([-7.7807,  5.3373], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([-7.8091,  5.4470], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([-7.1735,  5.5676], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([-7.4913,  5.5073], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([-7.6502,  5.4771], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([-7.7131,  5.4851], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([-7.7084,  5.4824], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([-7.7083,  5.4829], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([-7.7083,  5.4829], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([-7.7083,  5.4829], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([-7.7083,  5.4829], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([-7.7083,  5.4829], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([-7.7083,  5.4829], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([-7.7083,  5.4829], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([-7.7083,  5.4829], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([-7.7083,  5.4829], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([-7.7083,  5.4829], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([-7.7083,  5.4829], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([-7.7083,  5.4829], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([-7.7083,  5.4829], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "═════╩═══════════════════════════╩════════════════╩═════════════════╩═══════════════════════╩════════════════════╣\n",
      "Optimization results:                                                                                            ║ \n",
      "F = final iterate, B = Best (to tolerance), MF = Most Feasible                                                   ║ \n",
      "═════╦═══════════════════════════╦════════════════╦═════════════════╦═══════════════════════╦════════════════════╣\n",
      "   F ║          │                ║ -186.730908831 ║ 0.000000 │   -  ║    │       │          ║       │            ║ \n",
      "   B ║          │                ║ -186.730908831 ║ 0.000000 │   -  ║    │       │          ║       │            ║ \n",
      "  MF ║          │                ║ -186.730908831 ║ 0.000000 │   -  ║    │       │          ║       │            ║ \n",
      "═════╩═══════════════════════════╩════════════════╩═════════════════╩═══════════════════════╩════════════════════╣\n",
      "Iterations:              11                                                                                      ║ \n",
      "Function evaluations:    36                                                                                      ║ \n",
      "PyGRANSO termination code: 6 --- line search bracketed a minimizer but failed to satisfy Wolfe conditions at a   ║ \n",
      "(strictly) feasible point.  This may be an indication that approximate stationarity has been attained.           ║ \n",
      "═════════════════════════════════════════════════════════════════════════════════════════════════════════════════╝\n",
      "tensor([0.6420, 0.2598], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "\n",
      "\n",
      "\u001b[33m╔═════ QP SOLVER NOTICE ════════════════════════════════════════════════════════════════════════╗\n",
      "\u001b[0m\u001b[33m║  PyGRANSO requires a quadratic program (QP) solver that has a quadprog-compatible interface,  ║\n",
      "\u001b[0m\u001b[33m║  the default is osqp. Users may provide their own wrapper for the QP solver.                  ║\n",
      "\u001b[0m\u001b[33m║  To disable this notice, set opts.quadprog_info_msg = False                                   ║\n",
      "\u001b[0m\u001b[33m╚═══════════════════════════════════════════════════════════════════════════════════════════════╝\n",
      "\u001b[0m═════════════════════════════════════════════════════════════════════════════════════════════════════════════════╗\n",
      "PyGRANSO: A PyTorch-enabled port of GRANSO with auto-differentiation                                             ║ \n",
      "Version 1.2.0                                                                                                    ║ \n",
      "Licensed under the AGPLv3, Copyright (C) 2021-2022 Tim Mitchell and Buyun Liang                                  ║ \n",
      "═════════════════════════════════════════════════════════════════════════════════════════════════════════════════╣\n",
      "Problem specifications:                                                                                          ║ \n",
      " # of variables                     :   2                                                                        ║ \n",
      " # of inequality constraints        :   4                                                                        ║ \n",
      " # of equality constraints          :   0                                                                        ║ \n",
      "═════════════════════════════════════════════════════════════════════════════════════════════════════════════════╣\n",
      "\u001b[33mLimited-memory mode enabled with size = 150.                                                                    \u001b[0m ║ \n",
      "\u001b[33mNOTE: limited-memory mode is generally NOT                                                                      \u001b[0m ║ \n",
      "\u001b[33mrecommended for nonsmooth problems.                                                                             \u001b[0m ║ \n",
      "═════╦═══════════════════════════╦════════════════╦═════════════════╦═══════════════════════╦════════════════════╣\n",
      "     ║ <--- Penalty Function --> ║                ║ Total Violation ║ <--- Line Search ---> ║ <- Stationarity -> ║ \n",
      "Iter ║    Mu    │      Value     ║    Objective   ║   Ineq   │  Eq  ║ SD │ Evals │     t    ║ Grads │    Value   ║ \n",
      "═════╬═══════════════════════════╬════════════════╬═════════════════╬═══════════════════════╬════════════════════╣\n",
      "   0 ║ 1.000000 │ -5.35572191002 ║ -5.35572191002 ║ 0.000000 │   -  ║ -  │     1 │ 0.000000 ║     1 │ 71.23477   ║ \n",
      "tensor([71.8768, 21.3526], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([36.2594, 10.8062], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([18.4507,  5.5330], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([27.3551,  8.1696], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([22.9029,  6.8513], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([20.6768,  6.1921], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([19.5637,  5.8625], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([19.0072,  5.6977], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([18.7290,  5.6154], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([ 6.0873, -0.0110], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([12.4081,  2.8022], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([15.5686,  4.2088], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([17.1488,  4.9121], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([17.9389,  5.2637], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([18.3339,  5.4395], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([18.5314,  5.5274], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([19.6618,  2.2112], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([19.0966,  3.8693], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([18.8140,  4.6984], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([18.6727,  5.1129], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([18.6021,  5.3202], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([18.5668,  5.4238], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([18.5770,  5.4356], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([18.5873,  5.4474], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([18.6078,  5.4709], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([18.6194,  5.4801], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([18.6311,  5.4894], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([18.6317,  5.4893], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([18.6323,  5.4893], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([18.6334,  5.4892], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([18.6358,  5.4890], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([18.6334,  5.4883], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([18.6298,  5.4866], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([18.6271,  5.4848], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([18.6247,  5.4832], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([18.6222,  5.4818], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([18.6190,  5.4805], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([18.6151,  5.4796], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([18.6104,  5.4790], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([18.6052,  5.4790], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([18.5995,  5.4794], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([18.5933,  5.4802], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([18.5866,  5.4812], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([18.5793,  5.4823], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([18.5711,  5.4835], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([18.5618,  5.4847], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([18.5514,  5.4859], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([18.5396,  5.4870], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([18.5260,  5.4880], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([18.5104,  5.4889], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([18.4921,  5.4898], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([18.4702,  5.4907], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([18.4430,  5.4916], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([18.4067,  5.4929], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([18.3496,  5.4950], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([18.2926,  5.4970], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([18.1784,  5.5012], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([17.9501,  5.5094], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([17.4936,  5.5259], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([16.5804,  5.5589], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([14.7541,  5.6249], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([11.1015,  5.7568], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([3.7962, 6.0208], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([6.8585, 5.9096], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([4.5358, 5.9934], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([5.6971, 5.9515], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([5.1165, 5.9725], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([5.4068, 5.9620], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([6.2537, 5.9334], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([5.8302, 5.9477], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([5.6185, 5.9548], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([5.5127, 5.9584], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([5.4767, 5.9646], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([5.4483, 5.9785], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([5.4199, 5.9924], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([5.4291, 6.0112], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([5.4384, 6.0300], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([5.4570, 6.0675], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([5.4879, 6.0895], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([5.4829, 6.0878], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([5.4829, 6.0878], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([5.4829, 6.0878], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "═════╩═══════════════════════════╩════════════════╩═════════════════╩═══════════════════════╩════════════════════╣\n",
      "Optimization results:                                                                                            ║ \n",
      "F = final iterate, B = Best (to tolerance), MF = Most Feasible                                                   ║ \n",
      "═════╦═══════════════════════════╦════════════════╦═════════════════╦═══════════════════════╦════════════════════╣\n",
      "   F ║          │                ║ -123.576770859 ║ 0.000000 │   -  ║    │       │          ║       │            ║ \n",
      "   B ║          │                ║ -123.576770859 ║ 0.000000 │   -  ║    │       │          ║       │            ║ \n",
      "  MF ║          │                ║ -123.576770859 ║ 0.000000 │   -  ║    │       │          ║       │            ║ \n",
      "═════╩═══════════════════════════╩════════════════╩═════════════════╩═══════════════════════╩════════════════════╣\n",
      "Iterations:              40                                                                                      ║ \n",
      "Function evaluations:    83                                                                                      ║ \n",
      "PyGRANSO termination code: 0 --- converged to stationarity and feasibility tolerances.                           ║ \n",
      "═════════════════════════════════════════════════════════════════════════════════════════════════════════════════╝\n",
      "tensor([0.5776, 0.8946], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "\n",
      "\n",
      "\u001b[33m╔═════ QP SOLVER NOTICE ════════════════════════════════════════════════════════════════════════╗\n",
      "\u001b[0m\u001b[33m║  PyGRANSO requires a quadratic program (QP) solver that has a quadprog-compatible interface,  ║\n",
      "\u001b[0m\u001b[33m║  the default is osqp. Users may provide their own wrapper for the QP solver.                  ║\n",
      "\u001b[0m\u001b[33m║  To disable this notice, set opts.quadprog_info_msg = False                                   ║\n",
      "\u001b[0m\u001b[33m╚═══════════════════════════════════════════════════════════════════════════════════════════════╝\n",
      "\u001b[0m═════════════════════════════════════════════════════════════════════════════════════════════════════════════════╗\n",
      "PyGRANSO: A PyTorch-enabled port of GRANSO with auto-differentiation                                             ║ \n",
      "Version 1.2.0                                                                                                    ║ \n",
      "Licensed under the AGPLv3, Copyright (C) 2021-2022 Tim Mitchell and Buyun Liang                                  ║ \n",
      "═════════════════════════════════════════════════════════════════════════════════════════════════════════════════╣\n",
      "Problem specifications:                                                                                          ║ \n",
      " # of variables                     :   2                                                                        ║ \n",
      " # of inequality constraints        :   4                                                                        ║ \n",
      " # of equality constraints          :   0                                                                        ║ \n",
      "═════════════════════════════════════════════════════════════════════════════════════════════════════════════════╣\n",
      "\u001b[33mLimited-memory mode enabled with size = 150.                                                                    \u001b[0m ║ \n",
      "\u001b[33mNOTE: limited-memory mode is generally NOT                                                                      \u001b[0m ║ \n",
      "\u001b[33mrecommended for nonsmooth problems.                                                                             \u001b[0m ║ \n",
      "═════╦═══════════════════════════╦════════════════╦═════════════════╦═══════════════════════╦════════════════════╣\n",
      "     ║ <--- Penalty Function --> ║                ║ Total Violation ║ <--- Line Search ---> ║ <- Stationarity -> ║ \n",
      "Iter ║    Mu    │      Value     ║    Objective   ║   Ineq   │  Eq  ║ SD │ Evals │     t    ║ Grads │    Value   ║ \n",
      "═════╬═══════════════════════════╬════════════════╬═════════════════╬═══════════════════════╬════════════════════╣\n",
      "   0 ║ 1.000000 │  0.34956122112 ║  0.34956122112 ║ 0.000000 │   -  ║ -  │     1 │ 0.000000 ║     1 │ 81.35799   ║ \n",
      "tensor([-80.7804,   1.9079], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([-40.1014,   1.4013], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([-19.7619,   1.1480], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([-9.5922,  1.0213], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([-4.5073,  0.9580], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([-1.9649,  0.9263], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([-6.0557, -0.8266], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([-4.0103,  0.0498], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([-2.9876,  0.4881], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([-2.4762,  0.7072], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([-2.2205,  0.8167], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([-2.0927,  0.8715], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([-1.8063,  0.3979], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([-1.9495,  0.6347], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([-2.0211,  0.7531], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([-2.0030,  0.8278], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([-2.0080,  0.8218], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([-2.0071,  0.8217], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([-2.0072,  0.8218], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([-2.0072,  0.8218], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([-2.0072,  0.8218], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([-2.0072,  0.8218], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([-2.0072,  0.8218], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "═════╩═══════════════════════════╩════════════════╩═════════════════╩═══════════════════════╩════════════════════╣\n",
      "Optimization results:                                                                                            ║ \n",
      "F = final iterate, B = Best (to tolerance), MF = Most Feasible                                                   ║ \n",
      "═════╦═══════════════════════════╦════════════════╦═════════════════╦═══════════════════════╦════════════════════╣\n",
      "   F ║          │                ║ -23.1367162265 ║ 0.000000 │   -  ║    │       │          ║       │            ║ \n",
      "   B ║          │                ║ -23.1367162265 ║ 0.000000 │   -  ║    │       │          ║       │            ║ \n",
      "  MF ║          │                ║ -23.1367162265 ║ 0.000000 │   -  ║    │       │          ║       │            ║ \n",
      "═════╩═══════════════════════════╩════════════════╩═════════════════╩═══════════════════════╩════════════════════╣\n",
      "Iterations:              11                                                                                      ║ \n",
      "Function evaluations:    24                                                                                      ║ \n",
      "PyGRANSO termination code: 0 --- converged to stationarity and feasibility tolerances.                           ║ \n",
      "═════════════════════════════════════════════════════════════════════════════════════════════════════════════════╝\n",
      "tensor([0.2794, 0.2737], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "\n",
      "\n",
      "\u001b[33m╔═════ QP SOLVER NOTICE ════════════════════════════════════════════════════════════════════════╗\n",
      "\u001b[0m\u001b[33m║  PyGRANSO requires a quadratic program (QP) solver that has a quadprog-compatible interface,  ║\n",
      "\u001b[0m\u001b[33m║  the default is osqp. Users may provide their own wrapper for the QP solver.                  ║\n",
      "\u001b[0m\u001b[33m║  To disable this notice, set opts.quadprog_info_msg = False                                   ║\n",
      "\u001b[0m\u001b[33m╚═══════════════════════════════════════════════════════════════════════════════════════════════╝\n",
      "\u001b[0m═════════════════════════════════════════════════════════════════════════════════════════════════════════════════╗\n",
      "PyGRANSO: A PyTorch-enabled port of GRANSO with auto-differentiation                                             ║ \n",
      "Version 1.2.0                                                                                                    ║ \n",
      "Licensed under the AGPLv3, Copyright (C) 2021-2022 Tim Mitchell and Buyun Liang                                  ║ \n",
      "═════════════════════════════════════════════════════════════════════════════════════════════════════════════════╣\n",
      "Problem specifications:                                                                                          ║ \n",
      " # of variables                     :   2                                                                        ║ \n",
      " # of inequality constraints        :   4                                                                        ║ \n",
      " # of equality constraints          :   0                                                                        ║ \n",
      "═════════════════════════════════════════════════════════════════════════════════════════════════════════════════╣\n",
      "\u001b[33mLimited-memory mode enabled with size = 150.                                                                    \u001b[0m ║ \n",
      "\u001b[33mNOTE: limited-memory mode is generally NOT                                                                      \u001b[0m ║ \n",
      "\u001b[33mrecommended for nonsmooth problems.                                                                             \u001b[0m ║ \n",
      "═════╦═══════════════════════════╦════════════════╦═════════════════╦═══════════════════════╦════════════════════╣\n",
      "     ║ <--- Penalty Function --> ║                ║ Total Violation ║ <--- Line Search ---> ║ <- Stationarity -> ║ \n",
      "Iter ║    Mu    │      Value     ║    Objective   ║   Ineq   │  Eq  ║ SD │ Evals │     t    ║ Grads │    Value   ║ \n",
      "═════╬═══════════════════════════╬════════════════╬═════════════════╬═══════════════════════╬════════════════════╣\n",
      "   0 ║ 1.000000 │  12.5284230027 ║  12.5284230027 ║ 0.000000 │   -  ║ -  │     1 │ 0.000000 ║     1 │ 38.99041   ║ \n",
      "tensor([-34.3365, -38.7167], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([-17.0286, -19.2215], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([-8.3746, -9.4739], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([-12.7016, -14.3477], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([-14.8651, -16.7846], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([-16.0034, -16.0713], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([-15.4342, -16.4279], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([-15.1496, -16.6063], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([-16.4151, -13.3243], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([-15.7824, -14.9653], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([-15.4660, -15.7858], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([-15.3078, -16.1960], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([-15.2287, -16.4012], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([-15.1892, -16.5037], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([-15.1694, -16.5550], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([-15.1595, -16.5806], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([-14.9624, -16.4759], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([-15.0610, -16.5283], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([-15.0606, -16.5289], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([-15.0602, -16.5296], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([-15.0593, -16.5277], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([-15.0583, -16.5258], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([-15.0547, -16.5223], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([-15.0513, -16.5193], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([-15.0480, -16.5160], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([-15.0445, -16.5120], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([-15.0406, -16.5073], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([-15.0363, -16.5019], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([-15.0313, -16.4957], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([-15.0255, -16.4884], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([-15.0185, -16.4798], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([-15.0098, -16.4693], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([-14.9985, -16.4556], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([-14.9823, -16.4359], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([-14.9504, -16.3973], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([-14.9186, -16.3586], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([-14.8549, -16.2813], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([-14.7276, -16.1267], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([-14.4729, -15.8175], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([-14.2742, -15.6231], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([-14.0755, -15.4286], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([-13.8613, -15.3052], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([-13.9684, -15.3669], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([-14.0219, -15.3978], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([-13.9218, -15.4799], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([-13.8848, -15.4955], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([-13.8712, -15.4876], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([-13.8576, -15.4797], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([-13.8334, -15.4572], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([-13.8092, -15.4347], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([-13.7607, -15.3897], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([-13.6638, -15.2998], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([-13.4700, -15.1198], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([-13.0823, -14.7599], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([-12.3069, -14.0402], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([-10.7562, -12.6006], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([-7.6548, -9.7215], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([-1.4519, -3.9632], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([-2.5128, -4.9717], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([-1.9824, -4.4675], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([-1.7172, -4.2153], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([-1.5845, -4.0893], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([-1.5182, -4.0263], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([-1.4851, -3.9947], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([-1.4685, -3.9790], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([-1.4602, -3.9711], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([-1.4561, -3.9672], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([-1.4540, -3.9652], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([-1.4340, -3.9779], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([-1.4249, -3.9841], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([-1.4251, -3.9840], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([-1.4251, -3.9840], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([-1.4251, -3.9840], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([-1.4251, -3.9840], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([-1.4251, -3.9840], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([-1.4251, -3.9840], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([-1.4251, -3.9840], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([-1.4251, -3.9840], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([-1.4251, -3.9840], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "═════╩═══════════════════════════╩════════════════╩═════════════════╩═══════════════════════╩════════════════════╣\n",
      "Optimization results:                                                                                            ║ \n",
      "F = final iterate, B = Best (to tolerance), MF = Most Feasible                                                   ║ \n",
      "═════╦═══════════════════════════╦════════════════╦═════════════════╦═══════════════════════╦════════════════════╣\n",
      "   F ║          │                ║ -37.6560704131 ║ 0.000000 │   -  ║    │       │          ║       │            ║ \n",
      "   B ║          │                ║ -37.6560704131 ║ 0.000000 │   -  ║    │       │          ║       │            ║ \n",
      "  MF ║          │                ║ -37.6560704131 ║ 0.000000 │   -  ║    │       │          ║       │            ║ \n",
      "═════╩═══════════════════════════╩════════════════╩═════════════════╩═══════════════════════╩════════════════════╣\n",
      "Iterations:              32                                                                                      ║ \n",
      "Function evaluations:    80                                                                                      ║ \n",
      "PyGRANSO termination code: 6 --- line search bracketed a minimizer but failed to satisfy Wolfe conditions at a   ║ \n",
      "(strictly) feasible point.  This may be an indication that approximate stationarity has been attained.           ║ \n",
      "═════════════════════════════════════════════════════════════════════════════════════════════════════════════════╝\n",
      "tensor([0.7834, 0.5713], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "\n",
      "\n",
      "\u001b[33m╔═════ QP SOLVER NOTICE ════════════════════════════════════════════════════════════════════════╗\n",
      "\u001b[0m\u001b[33m║  PyGRANSO requires a quadratic program (QP) solver that has a quadprog-compatible interface,  ║\n",
      "\u001b[0m\u001b[33m║  the default is osqp. Users may provide their own wrapper for the QP solver.                  ║\n",
      "\u001b[0m\u001b[33m║  To disable this notice, set opts.quadprog_info_msg = False                                   ║\n",
      "\u001b[0m\u001b[33m╚═══════════════════════════════════════════════════════════════════════════════════════════════╝\n",
      "\u001b[0m═════════════════════════════════════════════════════════════════════════════════════════════════════════════════╗\n",
      "PyGRANSO: A PyTorch-enabled port of GRANSO with auto-differentiation                                             ║ \n",
      "Version 1.2.0                                                                                                    ║ \n",
      "Licensed under the AGPLv3, Copyright (C) 2021-2022 Tim Mitchell and Buyun Liang                                  ║ \n",
      "═════════════════════════════════════════════════════════════════════════════════════════════════════════════════╣\n",
      "Problem specifications:                                                                                          ║ \n",
      " # of variables                     :   2                                                                        ║ \n",
      " # of inequality constraints        :   4                                                                        ║ \n",
      " # of equality constraints          :   0                                                                        ║ \n",
      "═════════════════════════════════════════════════════════════════════════════════════════════════════════════════╣\n",
      "\u001b[33mLimited-memory mode enabled with size = 150.                                                                    \u001b[0m ║ \n",
      "\u001b[33mNOTE: limited-memory mode is generally NOT                                                                      \u001b[0m ║ \n",
      "\u001b[33mrecommended for nonsmooth problems.                                                                             \u001b[0m ║ \n",
      "═════╦═══════════════════════════╦════════════════╦═════════════════╦═══════════════════════╦════════════════════╣\n",
      "     ║ <--- Penalty Function --> ║                ║ Total Violation ║ <--- Line Search ---> ║ <- Stationarity -> ║ \n",
      "Iter ║    Mu    │      Value     ║    Objective   ║   Ineq   │  Eq  ║ SD │ Evals │     t    ║ Grads │    Value   ║ \n",
      "═════╬═══════════════════════════╬════════════════╬═════════════════╬═══════════════════════╬════════════════════╣\n",
      "   0 ║ 1.000000 │ -0.18292085556 ║ -0.18292085556 ║ 0.000000 │   -  ║ -  │     1 │ 0.000000 ║     1 │ 87.90009   ║ \n",
      "tensor([  1.0585, -87.3288], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([  0.9210, -43.3788], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([  0.8522, -21.4037], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([  0.8178, -10.4162], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([ 0.8596, -6.2591], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([ 0.8387, -8.3376], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([ 0.8491, -7.2984], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([ 0.8543, -6.7787], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([ 0.7240, -9.6792], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([ 0.7892, -8.2290], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([ 3.6426, -9.3085], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([ 2.2159, -8.7687], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([ 1.5025, -8.4988], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([ 1.1459, -8.3639], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([ 0.9675, -8.2964], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([ 0.8784, -8.2627], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([ 0.7004, -8.5830], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([ 0.7894, -8.4229], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([ 0.8339, -8.3428], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([ 0.8195, -8.2895], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([ 0.8220, -8.2904], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([ 0.8218, -8.2904], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([ 0.8218, -8.2904], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([ 0.8218, -8.2904], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([ 0.8218, -8.2904], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "═════╩═══════════════════════════╩════════════════╩═════════════════╩═══════════════════════╩════════════════════╣\n",
      "Optimization results:                                                                                            ║ \n",
      "F = final iterate, B = Best (to tolerance), MF = Most Feasible                                                   ║ \n",
      "═════╦═══════════════════════════╦════════════════╦═════════════════╦═══════════════════════╦════════════════════╣\n",
      "   F ║          │                ║ -23.1367162265 ║ 0.000000 │   -  ║    │       │          ║       │            ║ \n",
      "   B ║          │                ║ -26.5818319695 ║ 0.000000 │   -  ║    │       │          ║       │            ║ \n",
      "  MF ║          │                ║ -26.5818319695 ║ 0.000000 │   -  ║    │       │          ║       │            ║ \n",
      "═════╩═══════════════════════════╩════════════════╩═════════════════╩═══════════════════════╩════════════════════╣\n",
      "Iterations:              11                                                                                      ║ \n",
      "Function evaluations:    26                                                                                      ║ \n",
      "PyGRANSO termination code: 0 --- converged to stationarity and feasibility tolerances.                           ║ \n",
      "═════════════════════════════════════════════════════════════════════════════════════════════════════════════════╝\n",
      "tensor([0.2463, 0.8392], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "\n",
      "\n",
      "\u001b[33m╔═════ QP SOLVER NOTICE ════════════════════════════════════════════════════════════════════════╗\n",
      "\u001b[0m\u001b[33m║  PyGRANSO requires a quadratic program (QP) solver that has a quadprog-compatible interface,  ║\n",
      "\u001b[0m\u001b[33m║  the default is osqp. Users may provide their own wrapper for the QP solver.                  ║\n",
      "\u001b[0m\u001b[33m║  To disable this notice, set opts.quadprog_info_msg = False                                   ║\n",
      "\u001b[0m\u001b[33m╚═══════════════════════════════════════════════════════════════════════════════════════════════╝\n",
      "\u001b[0m═════════════════════════════════════════════════════════════════════════════════════════════════════════════════╗\n",
      "PyGRANSO: A PyTorch-enabled port of GRANSO with auto-differentiation                                             ║ \n",
      "Version 1.2.0                                                                                                    ║ \n",
      "Licensed under the AGPLv3, Copyright (C) 2021-2022 Tim Mitchell and Buyun Liang                                  ║ \n",
      "═════════════════════════════════════════════════════════════════════════════════════════════════════════════════╣\n",
      "Problem specifications:                                                                                          ║ \n",
      " # of variables                     :   2                                                                        ║ \n",
      " # of inequality constraints        :   4                                                                        ║ \n",
      " # of equality constraints          :   0                                                                        ║ \n",
      "═════════════════════════════════════════════════════════════════════════════════════════════════════════════════╣\n",
      "\u001b[33mLimited-memory mode enabled with size = 150.                                                                    \u001b[0m ║ \n",
      "\u001b[33mNOTE: limited-memory mode is generally NOT                                                                      \u001b[0m ║ \n",
      "\u001b[33mrecommended for nonsmooth problems.                                                                             \u001b[0m ║ \n",
      "═════╦═══════════════════════════╦════════════════╦═════════════════╦═══════════════════════╦════════════════════╣\n",
      "     ║ <--- Penalty Function --> ║                ║ Total Violation ║ <--- Line Search ---> ║ <- Stationarity -> ║ \n",
      "Iter ║    Mu    │      Value     ║    Objective   ║   Ineq   │  Eq  ║ SD │ Evals │     t    ║ Grads │    Value   ║ \n",
      "═════╬═══════════════════════════╬════════════════╬═════════════════╬═══════════════════════╬════════════════════╣\n",
      "   0 ║ 1.000000 │ -11.6831302269 ║ -11.6831302269 ║ 0.000000 │   -  ║ -  │     1 │ 0.000000 ║     1 │ 59.35411   ║ \n",
      "tensor([59.6004, -6.8728], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([29.9233, -3.0168], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([44.7619, -4.9448], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([37.3426, -3.9808], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([33.6330, -3.4988], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([31.7781, -3.2578], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([30.8507, -3.1373], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([30.3870, -3.0770], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([30.1552, -3.0469], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([30.0393, -3.0319], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([16.8685,  3.0569], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([2.3454e+01, 1.2533e-02], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([26.7466, -1.5097], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([28.3929, -2.2708], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([29.2161, -2.6513], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([29.6277, -2.8416], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([29.8335, -2.9367], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([29.9364, -2.9843], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([30.2854, -2.5039], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([30.1109, -2.7441], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([30.0236, -2.8642], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([29.9800, -2.9242], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([29.9582, -2.9543], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([29.9473, -2.9693], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([29.9418, -2.9768], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([29.9478, -2.9819], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([29.9538, -2.9870], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([29.9658, -2.9971], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([29.9678, -2.9991], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([29.9697, -3.0010], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([29.9681, -3.0001], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([29.9664, -2.9993], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([29.9631, -2.9987], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([29.9575, -2.9988], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([29.9522, -2.9998], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([29.9472, -3.0012], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([29.9424, -3.0027], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([29.9374, -3.0040], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([29.9314, -3.0051], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([29.9242, -3.0059], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([29.9158, -3.0062], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([29.9062, -3.0062], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([29.8952, -3.0059], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([29.8826, -3.0053], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([29.8679, -3.0044], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([29.8503, -3.0034], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([29.8285, -3.0023], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([29.7997, -3.0009], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([29.7572, -2.9990], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([29.6710, -2.9954], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([29.5848, -2.9917], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([29.4124, -2.9845], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([29.0676, -2.9700], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([28.3780, -2.9410], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([26.9987, -2.8829], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([24.2402, -2.7669], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([18.7231, -2.5347], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([ 7.6889, -2.0705], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([10.0000, -2.1688], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([10.0000, -2.1656], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([10.0000, -2.1623], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([10.0000, -2.1559], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([10.0000, -2.1430], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([10.0000, -2.1171], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([10.0000, -2.0655], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([10.0000, -1.9959], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([10.0000, -2.0080], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([10.0000, -2.0072], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([10.0000, -2.0072], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([10.0000, -2.0072], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "tensor([10.0000, -2.0072], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "═════╩═══════════════════════════╩════════════════╩═════════════════╩═══════════════════════╩════════════════════╣\n",
      "Optimization results:                                                                                            ║ \n",
      "F = final iterate, B = Best (to tolerance), MF = Most Feasible                                                   ║ \n",
      "═════╦═══════════════════════════╦════════════════╦═════════════════╦═══════════════════════╦════════════════════╣\n",
      "   F ║          │                ║ -20.6284575312 ║ 0.000000 │   -  ║    │       │          ║       │            ║ \n",
      "   B ║          │                ║ -20.6284575312 ║ 0.000000 │   -  ║    │       │          ║       │            ║ \n",
      "  MF ║          │                ║ -20.6284575312 ║ 0.000000 │   -  ║    │       │          ║       │            ║ \n",
      "═════╩═══════════════════════════╩════════════════╩═════════════════╩═══════════════════════╩════════════════════╣\n",
      "Iterations:              31                                                                                      ║ \n",
      "Function evaluations:    72                                                                                      ║ \n",
      "PyGRANSO termination code: 6 --- line search bracketed a minimizer but failed to satisfy Wolfe conditions at a   ║ \n",
      "(strictly) feasible point.  This may be an indication that approximate stationarity has been attained.           ║ \n",
      "═════════════════════════════════════════════════════════════════════════════════════════════════════════════════╝\n"
     ]
    }
   ],
   "source": [
    "outputs = run_pygranso(problem, trials=10)\n",
    "\n",
    "pygranso_results = pd.DataFrame(\n",
    "    outputs['final_results'],\n",
    "    columns=['x1', 'x2', 'f', 'b'],\n",
    ")\n",
    "pygranso_results = pygranso_results.add_prefix('pygranso_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "69521893-20d8-4d22-ae9b-00046ba0c803",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "******************************************************************************\n",
      "This program contains Ipopt, a library for large-scale nonlinear optimization.\n",
      " Ipopt is released as open source code under the Eclipse Public License (EPL).\n",
      "         For more information visit https://github.com/coin-or/Ipopt\n",
      "******************************************************************************\n",
      "\n"
     ]
    }
   ],
   "source": [
    "outputs = run_ipopt(problem, trials=10)\n",
    "\n",
    "ipopt_results = pd.DataFrame(outputs['final_results'], columns=['x1', 'x2', 'f'])\n",
    "ipopt_results = ipopt_results.add_prefix('ipopt_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d7494705-bdae-4438-ab9c-031576a4a5ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = run_dual_annealing(problem, trials=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c5207045-9934-4fd8-8790-24b5c7f9fa6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dual_annealing_results = pd.DataFrame(\n",
    "    outputs['final_results'], columns=['x1', 'x2', 'f']\n",
    ")\n",
    "dual_annealing_results = dual_annealing_results.add_prefix('dual_annealing_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5aa5dc04-9363-4f46-9b9f-63b4651196f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = run_differential_evolution(problem, trials=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c3a84b11-8e31-447e-8fd5-736b7efff1b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "de_results = pd.DataFrame(\n",
    "    outputs['final_results'],\n",
    "    columns=['x1', 'x2', 'f'],\n",
    ")\n",
    "de_results = de_results.add_prefix('differential_evolution_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "760269f5-304f-4e5b-a807-00eb34f1a0d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# de_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b8ccb053-68dc-4b42-ac24-54799b28c571",
   "metadata": {},
   "outputs": [],
   "source": [
    "# outputs = run_deeplifting(problem, trials=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fe88381d-97c5-4d97-a778-8717253e4920",
   "metadata": {},
   "outputs": [],
   "source": [
    "# deeplifting_results = pd.DataFrame(\n",
    "#     outputs['final_results'],\n",
    "#     columns=['x1', 'x2', 'f', 'b'],\n",
    "# )\n",
    "# deeplifting_results = deeplifting_results.add_prefix('deeplifting_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "98b86eb2-5840-41cb-82c4-4eed3177f1f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.concat(\n",
    "    [\n",
    "        ipopt_results,\n",
    "        pygranso_results,\n",
    "        dual_annealing_results,\n",
    "        de_results,\n",
    "        # deeplifting_results,\n",
    "    ],\n",
    "    axis=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3b011344-048f-48cd-971c-aa3adc0f7f98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ipopt_x1</th>\n",
       "      <th>ipopt_x2</th>\n",
       "      <th>ipopt_f</th>\n",
       "      <th>pygranso_x1</th>\n",
       "      <th>pygranso_x2</th>\n",
       "      <th>pygranso_f</th>\n",
       "      <th>pygranso_b</th>\n",
       "      <th>dual_annealing_x1</th>\n",
       "      <th>dual_annealing_x2</th>\n",
       "      <th>dual_annealing_f</th>\n",
       "      <th>differential_evolution_x1</th>\n",
       "      <th>differential_evolution_x2</th>\n",
       "      <th>differential_evolution_f</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-4.963181</td>\n",
       "      <td>-1.425128</td>\n",
       "      <td>-37.681120</td>\n",
       "      <td>4.858057</td>\n",
       "      <td>4.275983</td>\n",
       "      <td>-79.410913</td>\n",
       "      <td>-79.410913</td>\n",
       "      <td>-7.083506</td>\n",
       "      <td>-7.708314</td>\n",
       "      <td>-186.730909</td>\n",
       "      <td>4.858057</td>\n",
       "      <td>5.482864</td>\n",
       "      <td>-186.730909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.800321</td>\n",
       "      <td>1.805656</td>\n",
       "      <td>-39.588745</td>\n",
       "      <td>-8.290388</td>\n",
       "      <td>-9.780436</td>\n",
       "      <td>-16.286100</td>\n",
       "      <td>-16.286100</td>\n",
       "      <td>4.858057</td>\n",
       "      <td>5.482864</td>\n",
       "      <td>-186.730909</td>\n",
       "      <td>-7.083506</td>\n",
       "      <td>-1.425128</td>\n",
       "      <td>-186.730909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.800321</td>\n",
       "      <td>-2.510877</td>\n",
       "      <td>-52.050402</td>\n",
       "      <td>1.320004</td>\n",
       "      <td>7.104969</td>\n",
       "      <td>-10.978559</td>\n",
       "      <td>-10.978559</td>\n",
       "      <td>-7.083506</td>\n",
       "      <td>-1.425128</td>\n",
       "      <td>-186.730909</td>\n",
       "      <td>-1.425128</td>\n",
       "      <td>-7.083506</td>\n",
       "      <td>-186.730909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-6.478571</td>\n",
       "      <td>-2.007203</td>\n",
       "      <td>-52.553400</td>\n",
       "      <td>-2.007203</td>\n",
       "      <td>0.821784</td>\n",
       "      <td>-23.136716</td>\n",
       "      <td>-23.136716</td>\n",
       "      <td>-7.083506</td>\n",
       "      <td>4.858057</td>\n",
       "      <td>-186.730909</td>\n",
       "      <td>-7.083506</td>\n",
       "      <td>4.858057</td>\n",
       "      <td>-186.730909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.821784</td>\n",
       "      <td>-0.800321</td>\n",
       "      <td>-54.404865</td>\n",
       "      <td>-7.708314</td>\n",
       "      <td>5.482864</td>\n",
       "      <td>-186.730909</td>\n",
       "      <td>-186.730909</td>\n",
       "      <td>-7.708314</td>\n",
       "      <td>-0.800321</td>\n",
       "      <td>-186.730909</td>\n",
       "      <td>-0.800321</td>\n",
       "      <td>-7.708314</td>\n",
       "      <td>-186.730909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.334244</td>\n",
       "      <td>0.821784</td>\n",
       "      <td>-14.427456</td>\n",
       "      <td>5.482864</td>\n",
       "      <td>6.087800</td>\n",
       "      <td>-123.576771</td>\n",
       "      <td>-123.576771</td>\n",
       "      <td>-1.425128</td>\n",
       "      <td>5.482864</td>\n",
       "      <td>-186.730909</td>\n",
       "      <td>-0.800321</td>\n",
       "      <td>-7.708314</td>\n",
       "      <td>-186.730909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.821784</td>\n",
       "      <td>0.334244</td>\n",
       "      <td>-14.427456</td>\n",
       "      <td>-2.007203</td>\n",
       "      <td>0.821784</td>\n",
       "      <td>-23.136716</td>\n",
       "      <td>-23.136716</td>\n",
       "      <td>-1.425128</td>\n",
       "      <td>-7.083506</td>\n",
       "      <td>-186.730909</td>\n",
       "      <td>-7.708314</td>\n",
       "      <td>-7.083506</td>\n",
       "      <td>-186.730909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4.858057</td>\n",
       "      <td>0.334244</td>\n",
       "      <td>-49.518584</td>\n",
       "      <td>-1.425128</td>\n",
       "      <td>-3.983956</td>\n",
       "      <td>-37.656070</td>\n",
       "      <td>-37.656070</td>\n",
       "      <td>4.858057</td>\n",
       "      <td>-7.083506</td>\n",
       "      <td>-186.730909</td>\n",
       "      <td>5.482864</td>\n",
       "      <td>-7.708314</td>\n",
       "      <td>-186.730909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.320004</td>\n",
       "      <td>1.805656</td>\n",
       "      <td>-7.988759</td>\n",
       "      <td>0.821784</td>\n",
       "      <td>-8.290388</td>\n",
       "      <td>-23.136716</td>\n",
       "      <td>-26.581832</td>\n",
       "      <td>5.482864</td>\n",
       "      <td>-7.708314</td>\n",
       "      <td>-186.730909</td>\n",
       "      <td>5.482864</td>\n",
       "      <td>-7.708314</td>\n",
       "      <td>-186.730909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-0.800321</td>\n",
       "      <td>-1.425128</td>\n",
       "      <td>-186.730909</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>-2.007203</td>\n",
       "      <td>-20.628458</td>\n",
       "      <td>-20.628458</td>\n",
       "      <td>4.858057</td>\n",
       "      <td>-7.083506</td>\n",
       "      <td>-186.730909</td>\n",
       "      <td>-7.708314</td>\n",
       "      <td>-0.800321</td>\n",
       "      <td>-186.730909</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ipopt_x1  ipopt_x2     ipopt_f  pygranso_x1  pygranso_x2  pygranso_f  \\\n",
       "0 -4.963181 -1.425128  -37.681120     4.858057     4.275983  -79.410913   \n",
       "1 -0.800321  1.805656  -39.588745    -8.290388    -9.780436  -16.286100   \n",
       "2 -0.800321 -2.510877  -52.050402     1.320004     7.104969  -10.978559   \n",
       "3 -6.478571 -2.007203  -52.553400    -2.007203     0.821784  -23.136716   \n",
       "4  0.821784 -0.800321  -54.404865    -7.708314     5.482864 -186.730909   \n",
       "5  0.334244  0.821784  -14.427456     5.482864     6.087800 -123.576771   \n",
       "6  0.821784  0.334244  -14.427456    -2.007203     0.821784  -23.136716   \n",
       "7  4.858057  0.334244  -49.518584    -1.425128    -3.983956  -37.656070   \n",
       "8  1.320004  1.805656   -7.988759     0.821784    -8.290388  -23.136716   \n",
       "9 -0.800321 -1.425128 -186.730909    10.000000    -2.007203  -20.628458   \n",
       "\n",
       "   pygranso_b  dual_annealing_x1  dual_annealing_x2  dual_annealing_f  \\\n",
       "0  -79.410913          -7.083506          -7.708314       -186.730909   \n",
       "1  -16.286100           4.858057           5.482864       -186.730909   \n",
       "2  -10.978559          -7.083506          -1.425128       -186.730909   \n",
       "3  -23.136716          -7.083506           4.858057       -186.730909   \n",
       "4 -186.730909          -7.708314          -0.800321       -186.730909   \n",
       "5 -123.576771          -1.425128           5.482864       -186.730909   \n",
       "6  -23.136716          -1.425128          -7.083506       -186.730909   \n",
       "7  -37.656070           4.858057          -7.083506       -186.730909   \n",
       "8  -26.581832           5.482864          -7.708314       -186.730909   \n",
       "9  -20.628458           4.858057          -7.083506       -186.730909   \n",
       "\n",
       "   differential_evolution_x1  differential_evolution_x2  \\\n",
       "0                   4.858057                   5.482864   \n",
       "1                  -7.083506                  -1.425128   \n",
       "2                  -1.425128                  -7.083506   \n",
       "3                  -7.083506                   4.858057   \n",
       "4                  -0.800321                  -7.708314   \n",
       "5                  -0.800321                  -7.708314   \n",
       "6                  -7.708314                  -7.083506   \n",
       "7                   5.482864                  -7.708314   \n",
       "8                   5.482864                  -7.708314   \n",
       "9                  -7.708314                  -0.800321   \n",
       "\n",
       "   differential_evolution_f  \n",
       "0               -186.730909  \n",
       "1               -186.730909  \n",
       "2               -186.730909  \n",
       "3               -186.730909  \n",
       "4               -186.730909  \n",
       "5               -186.730909  \n",
       "6               -186.730909  \n",
       "7               -186.730909  \n",
       "8               -186.730909  \n",
       "9               -186.730909  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "486ee7c3-904f-4f5e-aa90-1ef3d3256da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the results with the actual global minimum\n",
    "columns = [\n",
    "    'ipopt_f',\n",
    "    'pygranso_f',\n",
    "    'dual_annealing_f',\n",
    "    'differential_evolution_f',\n",
    "    # 'deeplifting_f',\n",
    "]\n",
    "\n",
    "global_minimum = problem['global_minimum']\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 5))\n",
    "results[columns].plot(lw=3, figsize=(10, 5), ax=ax)\n",
    "ax.axhline(global_minimum, color='red', lw=3, label='Global Minimum')\n",
    "\n",
    "problem_title_name = ' '.join([str.capitalize() for str in problem_name.split('_')])\n",
    "ax.set_title(f'Comparison of Algorithms for {problem_title_name}')\n",
    "ax.set_xlabel('Trial')\n",
    "ax.set_ylabel('Objective Value')\n",
    "ax.grid()\n",
    "ax.legend()\n",
    "\n",
    "# fig.savefig(\n",
    "#     f'/Users/ryandevera/data-science/umn_environments/Deeplifting/images/{problem_name}.png'\n",
    "# )\n",
    "\n",
    "# # fig.savefig(\n",
    "# #     f'/home/seanschweiger/dl_testing/Deeplifting/images/{problem_name}.png'\n",
    "# # )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a22d24aa-c9d0-4ca7-bcb0-cf2dce891045",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # NLP written by GAMS Convert at 02/17/22 17:18:03\n",
    "# #\n",
    "# # Equation counts\n",
    "# #     Total        E        G        L        N        X        C        B\n",
    "# #         7        7        0        0        0        0        0        0\n",
    "# #\n",
    "# # Variable counts\n",
    "# #                  x        b        i      s1s      s2s       sc       si\n",
    "# #     Total     cont   binary  integer     sos1     sos2    scont     sint\n",
    "# #        14       14        0        0        0        0        0        0\n",
    "# # FX      0\n",
    "# #\n",
    "# # Nonzero counts\n",
    "# #     Total    const       NL\n",
    "# #        25        8       17\n",
    "# #\n",
    "# # Reformulation has removed 1 variable and 1 equation\n",
    "\n",
    "# from pyomo.environ import ConcreteModel, Var, Objective, Constraint, SolverFactory\n",
    "\n",
    "# model = m = ConcreteModel()\n",
    "\n",
    "# m.x1 = Var(within=Reals, bounds=(0,2), initialize=1.745)\n",
    "# m.x2 = Var(within=Reals, bounds=(0,1.6), initialize=1.2)\n",
    "# m.x3 = Var(within=Reals, bounds=(0,1.2), initialize=1.1)\n",
    "# m.x4 = Var(within=Reals, bounds=(0,5), initialize=3.048)\n",
    "# m.x5 = Var(within=Reals, bounds=(0,2), initialize=1.974)\n",
    "# m.x6 = Var(within=Reals, bounds=(0.85,0.93), initialize=0.893)\n",
    "# m.x7 = Var(within=Reals, bounds=(0.9,0.95), initialize=0.928)\n",
    "# m.x8 = Var(within=Reals, bounds=(3,12), initialize=8)\n",
    "# m.x9 = Var(within=Reals, bounds=(1.2,4), initialize=3.6)\n",
    "# m.x10 = Var(within=Reals, bounds=(1.45,1.62), initialize=1.45)\n",
    "# m.x11 = Var(within=Reals, bounds=(0.99,1.01010101010101), initialize=1)\n",
    "# m.x12 = Var(within=Reals, bounds=(0.99,1.01010101010101), initialize=1)\n",
    "# m.x13 = Var(within=Reals, bounds=(0.9,1.11111111111111), initialize=1)\n",
    "# m.x14 = Var(within=Reals, bounds=(0.99,1.01010101010101), initialize=1)\n",
    "\n",
    "# m.obj = Objective(sense=minimize, expr= -6.3 * m.x4 * m.x7 + 5.04 * m.x1 + 0.35\n",
    "#     * m.x2 + m.x3 + 3.36 * m.x5)\n",
    "\n",
    "# m.e1 = Constraint(expr= -0.819672131147541 * m.x1 + m.x4 - 0.819672131147541 *\n",
    "#     m.x5 == 0)\n",
    "# m.e2 = Constraint(expr= -m.x6 * (0.01 * m.x4 * m.x9 + m.x3) + 0.98 * m.x3 == 0)\n",
    "# m.e3 = Constraint(expr= -m.x1 * m.x8 + 10 * m.x2 + m.x5 == 0)\n",
    "# m.e4 = Constraint(expr= m.x4 * m.x11 - m.x1 * (-0.0067 * m.x8 * m.x8 + 0.13167\n",
    "#     * m.x8 + 1.12) == 0)\n",
    "# m.e5 = Constraint(expr= m.x7 * m.x12 - 0.01 * (-0.038 * m.x8 * m.x8 + 1.098 *\n",
    "#     m.x8) - 0.325 * m.x6 == 0.57425)\n",
    "# m.e6 = Constraint(expr= m.x9 * m.x13 + 22.2 * m.x10 == 35.82)\n",
    "# m.e7 = Constraint(expr= m.x10 * m.x14 - 3 * m.x7 == -1.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8254c6e-f8b2-41e5-ba3c-461cf27f6916",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Solve the problem\n",
    "# solver = SolverFactory('ipopt')\n",
    "# solver.solve(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feec1a6e-d1bb-42b2-9083-936014f73d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.obj()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
