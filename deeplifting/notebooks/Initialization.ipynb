{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "290f805d-f46f-4888-be62-79175a094fee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/ryandevera/data-science/umn_environments/Deeplifting\n"
     ]
    }
   ],
   "source": [
    "%cd ../.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e5b2cdef-b08b-42bd-9407-506f1c621b6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[36mLJ_data\u001b[m\u001b[m/                        \u001b[1m\u001b[36mhigh-dimension-search-results\u001b[m\u001b[m/\n",
      "LJ_data.tar                     \u001b[1m\u001b[36mimages\u001b[m\u001b[m/\n",
      "README.md                       \u001b[1m\u001b[36mjobs\u001b[m\u001b[m/\n",
      "\u001b[1m\u001b[36m__pycache__\u001b[m\u001b[m/                    \u001b[1m\u001b[36mlow-dimension-search-results\u001b[m\u001b[m/\n",
      "\u001b[1m\u001b[36malgorithm_compare_results\u001b[m\u001b[m/      \u001b[1m\u001b[36mmodels\u001b[m\u001b[m/\n",
      "\u001b[1m\u001b[36mdata\u001b[m\u001b[m/                           \u001b[1m\u001b[36mpaper-images\u001b[m\u001b[m/\n",
      "\u001b[1m\u001b[36mdata-queue\u001b[m\u001b[m/                     requirements.txt\n",
      "\u001b[1m\u001b[36mdata-queue-2023-09-24\u001b[m\u001b[m/          \u001b[1m\u001b[36mresults\u001b[m\u001b[m/\n",
      "\u001b[1m\u001b[36mdata-queue-2023-09-27\u001b[m\u001b[m/          \u001b[1m\u001b[36msearch_results\u001b[m\u001b[m/\n",
      "\u001b[1m\u001b[36mdeeplifting\u001b[m\u001b[m/                    tasks.py\n",
      "deeplifting.png                 test-low-dimension-results.png\n",
      "\u001b[1m\u001b[36mhigh-dimension-paper-results\u001b[m\u001b[m/\n"
     ]
    }
   ],
   "source": [
    "%ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4bd73321-ec1e-4e78-a040-43e53fcd0ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "\n",
    "from deeplifting.problems import PROBLEMS_BY_NAME\n",
    "from deeplifting.models import DeepliftingSkipMLP\n",
    "from deeplifting.optimization import deeplifting_predictions\n",
    "from deeplifting.utils import initialize_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bf3497d3-f45f-4681-aebc-80e56e3bcb8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "problem = PROBLEMS_BY_NAME['bukin_n6']\n",
    "output_size = problem['dimensions']\n",
    "\n",
    "# Set up the deeplifting model\n",
    "input_size = 1\n",
    "hidden_sizes = (128,) * 5\n",
    "bounds = problem['bounds']\n",
    "activation = 'sine'\n",
    "output_activation = 'leaky_relu'\n",
    "agg_function = 'sum'\n",
    "trial = 0\n",
    "\n",
    "model = DeepliftingSkipMLP(\n",
    "    input_size=input_size,\n",
    "    hidden_sizes=hidden_sizes,\n",
    "    output_size=output_size,\n",
    "    bounds=bounds,\n",
    "    skip_every_n=1,\n",
    "    activation=activation,\n",
    "    output_activation=output_activation,\n",
    "    agg_function=agg_function,\n",
    "    seed=trial,\n",
    ")\n",
    "\n",
    "# Need to setup an objective\n",
    "results = np.zeros((1, 1, 3))\n",
    "trial = 0\n",
    "\n",
    "objective = problem['objective']\n",
    "fn = lambda x: objective(x, results=results, trial=trial, version='pytorch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "99ed697e-a85d-4117-9717-dc34b0d1d777",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-6.8324,  2.1061], dtype=torch.float64,\n",
       "       grad_fn=<ReshapeAliasBackward0>)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = torch.randn(1, 5 * output_size).to(dtype=torch.double)\n",
    "model = model.to(dtype=torch.double)\n",
    "outputs = model(inputs=inputs)\n",
    "outputs.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3a3932de-732b-4835-844e-7ebb69534a4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-9.5119,  1.2911], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "x0 = initialize_vector(size=output_size, bounds=bounds)\n",
    "x0 = torch.from_numpy(x0)\n",
    "x0 = x0.to(dtype=torch.double)\n",
    "print(x0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a20dec45-7f26-4cd6-8ead-fa5bc2fcff0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We only want to manipulate the last linear layer weights\n",
    "for name, parameters in model.named_parameters():\n",
    "    if 'output' not in name:\n",
    "        parameters.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "42523a25-d7af-4422-b62d-36571044b3a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-9.5119,  1.2911], dtype=torch.float64,\n",
      "       grad_fn=<ReshapeAliasBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Now let's train the weights to get this outpu\n",
    "model.train()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-5)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "for epoch in range(1000):\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(inputs=inputs)\n",
    "    outputs = outputs.flatten()\n",
    "    loss = criterion(x0, outputs)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "\n",
    "print(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a7e02bd3-0d44-4c8f-9b13-4ff0360f9228",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now make sure all of the model weights are trainable\n",
    "for name, parameters in model.named_parameters():\n",
    "    if 'output' not in name:\n",
    "        parameters.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dbf284ac-79f1-4135-85ed-acf950f0b2e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-9.5119,  1.2911]], dtype=torch.float64, grad_fn=<StackBackward0>)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(inputs=inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af2cd10a-4686-47d2-822e-618fe025c35a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We only want to manipulate the last linear layer weights\n",
    "for name, parameters in model.named_parameters():\n",
    "    if 'output' not in name:\n",
    "        parameters.requires_grad = False\n",
    "\n",
    "# Now let's train the weights to get this outpu\n",
    "model.train()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-5)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "for epoch in range(1000):\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(inputs=inputs)\n",
    "    outputs = outputs.flatten()\n",
    "    loss = criterion(x0, outputs)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "# Now make sure all of the model weights are trainable\n",
    "for name, parameters in model.named_parameters():\n",
    "    if 'output' not in name:\n",
    "        parameters.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b476ce7c-c5e7-4b00-ac96-7e6a6fe8d190",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "completed_experiment = {\n",
    "    'low-dimension': {'ackley': 'Complete', 'bukin_n6': 'Complete'},\n",
    "    'high-dimension': {'ackley': {'ackley-3d': 'complete'}},\n",
    "}\n",
    "\n",
    "running_experiment = {'2d': {'ackley': 'Complete'}}\n",
    "\n",
    "completed_experiment == running_experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54862195-318e-43ee-8527-047abd78a9e3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeplifting",
   "language": "python",
   "name": "deeplifting"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
